{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Pruning implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = 'cnn-local-magnitude-unstruct'\n",
    "ITERATIONS = 3\n",
    "MAX_EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import foolbox as fb\n",
    "import random\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prune, Train Attack Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 3s 3ms/step - loss: 2.0222 - accuracy: 0.4350 - val_loss: 1.9362 - val_accuracy: 0.5209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.9085 - accuracy: 0.5496 - val_loss: 1.8340 - val_accuracy: 0.6233\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7775 - accuracy: 0.6827 - val_loss: 1.7173 - val_accuracy: 0.7453\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6958 - accuracy: 0.7661 - val_loss: 1.6495 - val_accuracy: 0.8129\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6163 - accuracy: 0.8459 - val_loss: 1.5984 - val_accuracy: 0.8625\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5912 - accuracy: 0.8702 - val_loss: 1.5709 - val_accuracy: 0.8905\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5751 - accuracy: 0.8874 - val_loss: 1.5619 - val_accuracy: 0.9006\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5652 - accuracy: 0.8967 - val_loss: 1.5539 - val_accuracy: 0.9083\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5584 - accuracy: 0.9032 - val_loss: 1.5507 - val_accuracy: 0.9106\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5532 - accuracy: 0.9082 - val_loss: 1.5423 - val_accuracy: 0.9200\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5470 - accuracy: 0.9145 - val_loss: 1.5393 - val_accuracy: 0.9213\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5445 - accuracy: 0.9172 - val_loss: 1.5406 - val_accuracy: 0.9210\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5394 - accuracy: 0.9223 - val_loss: 1.5335 - val_accuracy: 0.9291\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5398 - accuracy: 0.9220 - val_loss: 1.5428 - val_accuracy: 0.9194\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5350 - accuracy: 0.9267 - val_loss: 1.5301 - val_accuracy: 0.9314\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5344 - accuracy: 0.9266 - val_loss: 1.5329 - val_accuracy: 0.9284\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5306 - accuracy: 0.9306 - val_loss: 1.5261 - val_accuracy: 0.9360\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5299 - accuracy: 0.9311 - val_loss: 1.5270 - val_accuracy: 0.9339\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5262 - accuracy: 0.9348 - val_loss: 1.5200 - val_accuracy: 0.9414\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5248 - accuracy: 0.9366 - val_loss: 1.5242 - val_accuracy: 0.9368\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5214 - accuracy: 0.9399 - val_loss: 1.5201 - val_accuracy: 0.9409\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5206 - accuracy: 0.9408 - val_loss: 1.5196 - val_accuracy: 0.9417\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5214 - accuracy: 0.9400 - val_loss: 1.5235 - val_accuracy: 0.9378\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5190 - accuracy: 0.9419 - val_loss: 1.5231 - val_accuracy: 0.9381\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5172 - accuracy: 0.9444 - val_loss: 1.5169 - val_accuracy: 0.9439\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5145 - accuracy: 0.9469 - val_loss: 1.5125 - val_accuracy: 0.9489\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5132 - accuracy: 0.9481 - val_loss: 1.5134 - val_accuracy: 0.9485\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5138 - accuracy: 0.9477 - val_loss: 1.5129 - val_accuracy: 0.9486\n",
      "Epoch 28/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5138 - accuracy: 0.9475 - val_loss: 1.5125 - val_accuracy: 0.9494\n",
      "Epoch 29/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5120 - accuracy: 0.9495 - val_loss: 1.5085 - val_accuracy: 0.9530\n",
      "Epoch 30/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5122 - accuracy: 0.9488 - val_loss: 1.5069 - val_accuracy: 0.9541\n",
      "Epoch 31/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5093 - accuracy: 0.9520 - val_loss: 1.5053 - val_accuracy: 0.9563\n",
      "Epoch 32/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5078 - accuracy: 0.9535 - val_loss: 1.5088 - val_accuracy: 0.9525\n",
      "Epoch 33/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5083 - accuracy: 0.9530 - val_loss: 1.5073 - val_accuracy: 0.9542\n",
      "Epoch 34/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5084 - accuracy: 0.9530 - val_loss: 1.5061 - val_accuracy: 0.9549\n",
      "Epoch 35/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5070 - accuracy: 0.9542 - val_loss: 1.5119 - val_accuracy: 0.9499\n",
      "Epoch 36/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5092 - accuracy: 0.9521 - val_loss: 1.5081 - val_accuracy: 0.9536\n",
      "Epoch 37/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5066 - accuracy: 0.9547 - val_loss: 1.5037 - val_accuracy: 0.9582\n",
      "Epoch 38/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5053 - accuracy: 0.9560 - val_loss: 1.5042 - val_accuracy: 0.9565\n",
      "Epoch 39/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5043 - accuracy: 0.9569 - val_loss: 1.5126 - val_accuracy: 0.9483\n",
      "Epoch 40/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5054 - accuracy: 0.9557 - val_loss: 1.5039 - val_accuracy: 0.9575\n",
      "Epoch 41/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5030 - accuracy: 0.9583 - val_loss: 1.5056 - val_accuracy: 0.9546\n",
      "Epoch 42/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5054 - accuracy: 0.9560 - val_loss: 1.5012 - val_accuracy: 0.9597\n",
      "Epoch 43/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5026 - accuracy: 0.9585 - val_loss: 1.5010 - val_accuracy: 0.9598\n",
      "Epoch 44/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5025 - accuracy: 0.9588 - val_loss: 1.5018 - val_accuracy: 0.9596\n",
      "Epoch 45/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4998 - accuracy: 0.9614 - val_loss: 1.5040 - val_accuracy: 0.9572\n",
      "Epoch 46/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5016 - accuracy: 0.9598 - val_loss: 1.5011 - val_accuracy: 0.9602\n",
      "Epoch 47/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4992 - accuracy: 0.9619 - val_loss: 1.5013 - val_accuracy: 0.9593\n",
      "Epoch 48/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4985 - accuracy: 0.9627 - val_loss: 1.5038 - val_accuracy: 0.9574\n",
      "Epoch 49/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5008 - accuracy: 0.9604 - val_loss: 1.5011 - val_accuracy: 0.9600\n",
      "Epoch 50/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4975 - accuracy: 0.9637 - val_loss: 1.4994 - val_accuracy: 0.9625\n",
      "Epoch 51/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4988 - accuracy: 0.9626 - val_loss: 1.5014 - val_accuracy: 0.9603\n",
      "Epoch 52/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4992 - accuracy: 0.9619 - val_loss: 1.5033 - val_accuracy: 0.9577\n",
      "Epoch 53/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4967 - accuracy: 0.9646 - val_loss: 1.5011 - val_accuracy: 0.9607\n",
      "Epoch 54/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4963 - accuracy: 0.9648 - val_loss: 1.4960 - val_accuracy: 0.9652\n",
      "Epoch 55/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4968 - accuracy: 0.9641 - val_loss: 1.4982 - val_accuracy: 0.9626\n",
      "Epoch 56/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4962 - accuracy: 0.9649 - val_loss: 1.4979 - val_accuracy: 0.9635\n",
      "Epoch 57/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4956 - accuracy: 0.9657 - val_loss: 1.4968 - val_accuracy: 0.9645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4966 - accuracy: 0.9645 - val_loss: 1.4999 - val_accuracy: 0.9617\n",
      "Epoch 59/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4967 - accuracy: 0.9646 - val_loss: 1.4965 - val_accuracy: 0.9647\n",
      "Epoch 60/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4953 - accuracy: 0.9659 - val_loss: 1.4980 - val_accuracy: 0.9634\n",
      "Epoch 61/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4945 - accuracy: 0.9667 - val_loss: 1.4962 - val_accuracy: 0.9648\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/master-thesis/lib/python3.8/site-packages/foolbox/models/tensorflow.py:13: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [02:49, 169.96s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.9066 - accuracy: 0.5512 - val_loss: 1.8092 - val_accuracy: 0.6488\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7710 - accuracy: 0.6894 - val_loss: 1.7364 - val_accuracy: 0.7228\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6979 - accuracy: 0.7642 - val_loss: 1.6373 - val_accuracy: 0.8265\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6179 - accuracy: 0.8441 - val_loss: 1.6040 - val_accuracy: 0.8584\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5949 - accuracy: 0.8671 - val_loss: 1.5777 - val_accuracy: 0.8842\n",
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6460 - accuracy: 0.8173 - val_loss: 1.5991 - val_accuracy: 0.8630\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5915 - accuracy: 0.8709 - val_loss: 1.5769 - val_accuracy: 0.8854\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5771 - accuracy: 0.8850 - val_loss: 1.5640 - val_accuracy: 0.8973\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5655 - accuracy: 0.8961 - val_loss: 1.5617 - val_accuracy: 0.9009\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5589 - accuracy: 0.9026 - val_loss: 1.5543 - val_accuracy: 0.9077\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5535 - accuracy: 0.9085 - val_loss: 1.5518 - val_accuracy: 0.9102\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5489 - accuracy: 0.9128 - val_loss: 1.5459 - val_accuracy: 0.9156\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5458 - accuracy: 0.9162 - val_loss: 1.5454 - val_accuracy: 0.9160\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5427 - accuracy: 0.9189 - val_loss: 1.5444 - val_accuracy: 0.9167\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5392 - accuracy: 0.9222 - val_loss: 1.5389 - val_accuracy: 0.9224\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5368 - accuracy: 0.9250 - val_loss: 1.5338 - val_accuracy: 0.9284\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5346 - accuracy: 0.9269 - val_loss: 1.5374 - val_accuracy: 0.9239\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5331 - accuracy: 0.9286 - val_loss: 1.5306 - val_accuracy: 0.9323\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5284 - accuracy: 0.9334 - val_loss: 1.5320 - val_accuracy: 0.9294\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5281 - accuracy: 0.9334 - val_loss: 1.5263 - val_accuracy: 0.9353\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5244 - accuracy: 0.9373 - val_loss: 1.5258 - val_accuracy: 0.9359\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5240 - accuracy: 0.9371 - val_loss: 1.5247 - val_accuracy: 0.9374\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5219 - accuracy: 0.9396 - val_loss: 1.5269 - val_accuracy: 0.9346\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5227 - accuracy: 0.9387 - val_loss: 1.5232 - val_accuracy: 0.9383\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5203 - accuracy: 0.9408 - val_loss: 1.5226 - val_accuracy: 0.9397\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5191 - accuracy: 0.9422 - val_loss: 1.5225 - val_accuracy: 0.9389\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5203 - accuracy: 0.9407 - val_loss: 1.5199 - val_accuracy: 0.9407\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5175 - accuracy: 0.9439 - val_loss: 1.5179 - val_accuracy: 0.9439\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5169 - accuracy: 0.9449 - val_loss: 1.5207 - val_accuracy: 0.9408\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5160 - accuracy: 0.9452 - val_loss: 1.5154 - val_accuracy: 0.9454\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5152 - accuracy: 0.9466 - val_loss: 1.5160 - val_accuracy: 0.9448\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5128 - accuracy: 0.9487 - val_loss: 1.5162 - val_accuracy: 0.9451\n",
      "Epoch 28/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5125 - accuracy: 0.9490 - val_loss: 1.5145 - val_accuracy: 0.9463\n",
      "Epoch 29/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5117 - accuracy: 0.9495 - val_loss: 1.5156 - val_accuracy: 0.9460\n",
      "Epoch 30/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5107 - accuracy: 0.9505 - val_loss: 1.5152 - val_accuracy: 0.9455\n",
      "Epoch 31/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5106 - accuracy: 0.9509 - val_loss: 1.5131 - val_accuracy: 0.9476\n",
      "Epoch 32/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5106 - accuracy: 0.9508 - val_loss: 1.5135 - val_accuracy: 0.9474\n",
      "Epoch 33/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5089 - accuracy: 0.9525 - val_loss: 1.5123 - val_accuracy: 0.9489\n",
      "Epoch 34/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5086 - accuracy: 0.9525 - val_loss: 1.5128 - val_accuracy: 0.9485\n",
      "Epoch 35/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5092 - accuracy: 0.9523 - val_loss: 1.5077 - val_accuracy: 0.9536\n",
      "Epoch 36/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5080 - accuracy: 0.9535 - val_loss: 1.5102 - val_accuracy: 0.9506\n",
      "Epoch 37/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5085 - accuracy: 0.9528 - val_loss: 1.5104 - val_accuracy: 0.9512\n",
      "Epoch 38/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5065 - accuracy: 0.9550 - val_loss: 1.5072 - val_accuracy: 0.9540\n",
      "Epoch 39/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5046 - accuracy: 0.9569 - val_loss: 1.5057 - val_accuracy: 0.9558\n",
      "Epoch 40/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5039 - accuracy: 0.9574 - val_loss: 1.5083 - val_accuracy: 0.9516\n",
      "Epoch 41/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5030 - accuracy: 0.9583 - val_loss: 1.5064 - val_accuracy: 0.9549\n",
      "Epoch 42/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5023 - accuracy: 0.9594 - val_loss: 1.5053 - val_accuracy: 0.9559\n",
      "Epoch 43/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5032 - accuracy: 0.9578 - val_loss: 1.5045 - val_accuracy: 0.9569\n",
      "Epoch 44/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5010 - accuracy: 0.9605 - val_loss: 1.5039 - val_accuracy: 0.9569\n",
      "Epoch 45/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5018 - accuracy: 0.9594 - val_loss: 1.5063 - val_accuracy: 0.9543\n",
      "Epoch 46/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5009 - accuracy: 0.9606 - val_loss: 1.5041 - val_accuracy: 0.9575\n",
      "Epoch 47/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5002 - accuracy: 0.9614 - val_loss: 1.5039 - val_accuracy: 0.9575\n",
      "Epoch 48/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4999 - accuracy: 0.9614 - val_loss: 1.5053 - val_accuracy: 0.9561\n",
      "Epoch 49/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5015 - accuracy: 0.9600 - val_loss: 1.5045 - val_accuracy: 0.9575\n",
      "Epoch 50/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5007 - accuracy: 0.9608 - val_loss: 1.5040 - val_accuracy: 0.9575\n",
      "Epoch 51/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4991 - accuracy: 0.9619 - val_loss: 1.5031 - val_accuracy: 0.9585\n",
      "Epoch 52/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4984 - accuracy: 0.9631 - val_loss: 1.5029 - val_accuracy: 0.9584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4970 - accuracy: 0.9648 - val_loss: 1.5013 - val_accuracy: 0.9600\n",
      "Epoch 54/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4980 - accuracy: 0.9635 - val_loss: 1.5035 - val_accuracy: 0.9578\n",
      "Epoch 55/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4969 - accuracy: 0.9644 - val_loss: 1.5003 - val_accuracy: 0.9617\n",
      "Epoch 56/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4982 - accuracy: 0.9630 - val_loss: 1.5004 - val_accuracy: 0.9600\n",
      "Epoch 57/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4956 - accuracy: 0.9658 - val_loss: 1.5019 - val_accuracy: 0.9592\n",
      "Epoch 58/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4970 - accuracy: 0.9643 - val_loss: 1.5025 - val_accuracy: 0.9584\n",
      "Epoch 59/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4964 - accuracy: 0.9649 - val_loss: 1.5005 - val_accuracy: 0.9609\n",
      "Epoch 60/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4950 - accuracy: 0.9663 - val_loss: 1.4998 - val_accuracy: 0.9618\n",
      "Epoch 61/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4951 - accuracy: 0.9666 - val_loss: 1.5007 - val_accuracy: 0.9601\n",
      "Epoch 62/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4954 - accuracy: 0.9661 - val_loss: 1.5014 - val_accuracy: 0.9604\n",
      "Epoch 63/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4941 - accuracy: 0.9675 - val_loss: 1.4986 - val_accuracy: 0.9631\n",
      "Epoch 64/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4940 - accuracy: 0.9675 - val_loss: 1.4978 - val_accuracy: 0.9632\n",
      "Epoch 65/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4949 - accuracy: 0.9664 - val_loss: 1.5042 - val_accuracy: 0.9569\n",
      "Epoch 66/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4944 - accuracy: 0.9669 - val_loss: 1.4989 - val_accuracy: 0.9625\n",
      "Epoch 67/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4943 - accuracy: 0.9667 - val_loss: 1.5002 - val_accuracy: 0.9611\n",
      "Epoch 68/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4917 - accuracy: 0.9698 - val_loss: 1.4973 - val_accuracy: 0.9639\n",
      "Epoch 69/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4935 - accuracy: 0.9676 - val_loss: 1.4966 - val_accuracy: 0.9644\n",
      "Epoch 70/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4918 - accuracy: 0.9695 - val_loss: 1.4968 - val_accuracy: 0.9650\n",
      "Epoch 71/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4931 - accuracy: 0.9683 - val_loss: 1.4995 - val_accuracy: 0.9617\n",
      "Epoch 72/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4920 - accuracy: 0.9692 - val_loss: 1.4966 - val_accuracy: 0.9644\n",
      "Epoch 73/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4935 - accuracy: 0.9679 - val_loss: 1.4958 - val_accuracy: 0.9657\n",
      "Epoch 74/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4916 - accuracy: 0.9699 - val_loss: 1.4956 - val_accuracy: 0.9658\n",
      "Epoch 75/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4919 - accuracy: 0.9695 - val_loss: 1.4962 - val_accuracy: 0.9650\n",
      "Epoch 76/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4907 - accuracy: 0.9704 - val_loss: 1.4947 - val_accuracy: 0.9667\n",
      "Epoch 77/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4910 - accuracy: 0.9706 - val_loss: 1.4962 - val_accuracy: 0.9649\n",
      "Epoch 78/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4904 - accuracy: 0.9711 - val_loss: 1.4969 - val_accuracy: 0.9640\n",
      "Epoch 79/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4912 - accuracy: 0.9703 - val_loss: 1.4994 - val_accuracy: 0.9616\n",
      "Epoch 80/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4912 - accuracy: 0.9698 - val_loss: 1.4959 - val_accuracy: 0.9652\n",
      "Epoch 81/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4892 - accuracy: 0.9721 - val_loss: 1.4956 - val_accuracy: 0.9652\n",
      "Epoch 82/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4892 - accuracy: 0.9722 - val_loss: 1.4948 - val_accuracy: 0.9664\n",
      "Epoch 83/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4896 - accuracy: 0.9717 - val_loss: 1.4954 - val_accuracy: 0.9656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [06:54, 192.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.9282 - accuracy: 0.5298 - val_loss: 1.8878 - val_accuracy: 0.5710\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8268 - accuracy: 0.6330 - val_loss: 1.7854 - val_accuracy: 0.6740\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7786 - accuracy: 0.6813 - val_loss: 1.7686 - val_accuracy: 0.6917\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7588 - accuracy: 0.7008 - val_loss: 1.7450 - val_accuracy: 0.7155\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7441 - accuracy: 0.7157 - val_loss: 1.7333 - val_accuracy: 0.7271\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7790 - accuracy: 0.6816 - val_loss: 1.7418 - val_accuracy: 0.7183\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7444 - accuracy: 0.7157 - val_loss: 1.7335 - val_accuracy: 0.7284\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7344 - accuracy: 0.7255 - val_loss: 1.7275 - val_accuracy: 0.7323\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7287 - accuracy: 0.7314 - val_loss: 1.7219 - val_accuracy: 0.7390\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7241 - accuracy: 0.7358 - val_loss: 1.7180 - val_accuracy: 0.7424\n",
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.9646 - accuracy: 0.4949 - val_loss: 1.8451 - val_accuracy: 0.6188\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8146 - accuracy: 0.6478 - val_loss: 1.7946 - val_accuracy: 0.6685\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7826 - accuracy: 0.6785 - val_loss: 1.7750 - val_accuracy: 0.6858\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7650 - accuracy: 0.6963 - val_loss: 1.7619 - val_accuracy: 0.6985\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7525 - accuracy: 0.7085 - val_loss: 1.7481 - val_accuracy: 0.7132\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7438 - accuracy: 0.7177 - val_loss: 1.7424 - val_accuracy: 0.7185\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7378 - accuracy: 0.7232 - val_loss: 1.7363 - val_accuracy: 0.7237\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7311 - accuracy: 0.7295 - val_loss: 1.7301 - val_accuracy: 0.7312\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7258 - accuracy: 0.7354 - val_loss: 1.7292 - val_accuracy: 0.7314\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7225 - accuracy: 0.7385 - val_loss: 1.7240 - val_accuracy: 0.7360\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7191 - accuracy: 0.7418 - val_loss: 1.7203 - val_accuracy: 0.7401\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7168 - accuracy: 0.7439 - val_loss: 1.7187 - val_accuracy: 0.7416\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7149 - accuracy: 0.7455 - val_loss: 1.7175 - val_accuracy: 0.7422\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7119 - accuracy: 0.7486 - val_loss: 1.7157 - val_accuracy: 0.7449\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7105 - accuracy: 0.7503 - val_loss: 1.7141 - val_accuracy: 0.7456\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7093 - accuracy: 0.7511 - val_loss: 1.7145 - val_accuracy: 0.7457\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7080 - accuracy: 0.7523 - val_loss: 1.7119 - val_accuracy: 0.7483\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7055 - accuracy: 0.7548 - val_loss: 1.7118 - val_accuracy: 0.7480\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7048 - accuracy: 0.7552 - val_loss: 1.7107 - val_accuracy: 0.7488\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7032 - accuracy: 0.7575 - val_loss: 1.7079 - val_accuracy: 0.7514\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7028 - accuracy: 0.7574 - val_loss: 1.7090 - val_accuracy: 0.7503\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7016 - accuracy: 0.7585 - val_loss: 1.7058 - val_accuracy: 0.7540\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6999 - accuracy: 0.7600 - val_loss: 1.7049 - val_accuracy: 0.7552\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6987 - accuracy: 0.7615 - val_loss: 1.7054 - val_accuracy: 0.7543\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6979 - accuracy: 0.7627 - val_loss: 1.7056 - val_accuracy: 0.7540\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6973 - accuracy: 0.7630 - val_loss: 1.7046 - val_accuracy: 0.7547\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6964 - accuracy: 0.7637 - val_loss: 1.7043 - val_accuracy: 0.7559\n",
      "Epoch 28/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6946 - accuracy: 0.7655 - val_loss: 1.6974 - val_accuracy: 0.7629\n",
      "Epoch 29/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6800 - accuracy: 0.7804 - val_loss: 1.6715 - val_accuracy: 0.7898\n",
      "Epoch 30/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6525 - accuracy: 0.8093 - val_loss: 1.6454 - val_accuracy: 0.8152\n",
      "Epoch 31/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6348 - accuracy: 0.8268 - val_loss: 1.6351 - val_accuracy: 0.8256\n",
      "Epoch 32/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6285 - accuracy: 0.8330 - val_loss: 1.6268 - val_accuracy: 0.8357\n",
      "Epoch 33/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6243 - accuracy: 0.8375 - val_loss: 1.6263 - val_accuracy: 0.8349\n",
      "Epoch 34/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6208 - accuracy: 0.8408 - val_loss: 1.6228 - val_accuracy: 0.8389\n",
      "Epoch 35/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6184 - accuracy: 0.8434 - val_loss: 1.6189 - val_accuracy: 0.8417\n",
      "Epoch 36/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6157 - accuracy: 0.8453 - val_loss: 1.6173 - val_accuracy: 0.8434\n",
      "Epoch 37/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6143 - accuracy: 0.8471 - val_loss: 1.6165 - val_accuracy: 0.8448\n",
      "Epoch 38/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6113 - accuracy: 0.8501 - val_loss: 1.6132 - val_accuracy: 0.8482\n",
      "Epoch 39/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6113 - accuracy: 0.8499 - val_loss: 1.6150 - val_accuracy: 0.8457\n",
      "Epoch 40/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6102 - accuracy: 0.8511 - val_loss: 1.6119 - val_accuracy: 0.8493\n",
      "Epoch 41/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6090 - accuracy: 0.8523 - val_loss: 1.6119 - val_accuracy: 0.8498\n",
      "Epoch 42/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6079 - accuracy: 0.8531 - val_loss: 1.6093 - val_accuracy: 0.8514\n",
      "Epoch 43/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6056 - accuracy: 0.8559 - val_loss: 1.6108 - val_accuracy: 0.8505\n",
      "Epoch 44/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6056 - accuracy: 0.8554 - val_loss: 1.6081 - val_accuracy: 0.8526\n",
      "Epoch 45/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6044 - accuracy: 0.8568 - val_loss: 1.6092 - val_accuracy: 0.8510\n",
      "Epoch 46/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6039 - accuracy: 0.8573 - val_loss: 1.6090 - val_accuracy: 0.8516\n",
      "Epoch 47/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6023 - accuracy: 0.8588 - val_loss: 1.6077 - val_accuracy: 0.8537\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6022 - accuracy: 0.8591 - val_loss: 1.6079 - val_accuracy: 0.8527\n",
      "Epoch 49/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6010 - accuracy: 0.8602 - val_loss: 1.6071 - val_accuracy: 0.8530\n",
      "Epoch 50/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6007 - accuracy: 0.8606 - val_loss: 1.6065 - val_accuracy: 0.8540\n",
      "Epoch 51/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6003 - accuracy: 0.8609 - val_loss: 1.6071 - val_accuracy: 0.8540\n",
      "Epoch 52/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5992 - accuracy: 0.8616 - val_loss: 1.6037 - val_accuracy: 0.8575\n",
      "Epoch 53/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5976 - accuracy: 0.8633 - val_loss: 1.6052 - val_accuracy: 0.8547\n",
      "Epoch 54/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5973 - accuracy: 0.8637 - val_loss: 1.6032 - val_accuracy: 0.8585\n",
      "Epoch 55/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5963 - accuracy: 0.8644 - val_loss: 1.6039 - val_accuracy: 0.8569\n",
      "Epoch 56/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5968 - accuracy: 0.8641 - val_loss: 1.6036 - val_accuracy: 0.8572\n",
      "Epoch 57/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5962 - accuracy: 0.8647 - val_loss: 1.6035 - val_accuracy: 0.8576\n",
      "Epoch 58/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5958 - accuracy: 0.8655 - val_loss: 1.6033 - val_accuracy: 0.8579\n",
      "Epoch 59/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5953 - accuracy: 0.8658 - val_loss: 1.6024 - val_accuracy: 0.8576\n",
      "Epoch 60/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5937 - accuracy: 0.8675 - val_loss: 1.6018 - val_accuracy: 0.8589\n",
      "Epoch 61/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5931 - accuracy: 0.8680 - val_loss: 1.6010 - val_accuracy: 0.8598\n",
      "Epoch 62/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5932 - accuracy: 0.8677 - val_loss: 1.6022 - val_accuracy: 0.8574\n",
      "Epoch 63/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5926 - accuracy: 0.8688 - val_loss: 1.6007 - val_accuracy: 0.8597\n",
      "Epoch 64/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5919 - accuracy: 0.8692 - val_loss: 1.6007 - val_accuracy: 0.8601\n",
      "Epoch 65/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5922 - accuracy: 0.8689 - val_loss: 1.6013 - val_accuracy: 0.8590\n",
      "Epoch 66/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5917 - accuracy: 0.8694 - val_loss: 1.6017 - val_accuracy: 0.8599\n",
      "Epoch 67/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5905 - accuracy: 0.8706 - val_loss: 1.5992 - val_accuracy: 0.8617\n",
      "Epoch 68/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5900 - accuracy: 0.8707 - val_loss: 1.5992 - val_accuracy: 0.8618\n",
      "Epoch 69/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5898 - accuracy: 0.8715 - val_loss: 1.5994 - val_accuracy: 0.8624\n",
      "Epoch 70/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5896 - accuracy: 0.8715 - val_loss: 1.6003 - val_accuracy: 0.8599\n",
      "Epoch 71/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5895 - accuracy: 0.8715 - val_loss: 1.6003 - val_accuracy: 0.8603\n",
      "Epoch 72/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5885 - accuracy: 0.8725 - val_loss: 1.6007 - val_accuracy: 0.8604\n",
      "Epoch 73/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5878 - accuracy: 0.8733 - val_loss: 1.5985 - val_accuracy: 0.8621\n",
      "Epoch 74/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5876 - accuracy: 0.8735 - val_loss: 1.5995 - val_accuracy: 0.8610\n",
      "Epoch 75/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5877 - accuracy: 0.8734 - val_loss: 1.5992 - val_accuracy: 0.8611\n",
      "Epoch 76/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5873 - accuracy: 0.8737 - val_loss: 1.5987 - val_accuracy: 0.8622\n",
      "Epoch 77/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5875 - accuracy: 0.8738 - val_loss: 1.5980 - val_accuracy: 0.8628\n",
      "Epoch 78/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5866 - accuracy: 0.8745 - val_loss: 1.5985 - val_accuracy: 0.8616\n",
      "Epoch 79/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5864 - accuracy: 0.8746 - val_loss: 1.5968 - val_accuracy: 0.8637\n",
      "Epoch 80/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5860 - accuracy: 0.8748 - val_loss: 1.5973 - val_accuracy: 0.8628\n",
      "Epoch 81/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5859 - accuracy: 0.8751 - val_loss: 1.5981 - val_accuracy: 0.8621\n",
      "Epoch 82/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5853 - accuracy: 0.8757 - val_loss: 1.5968 - val_accuracy: 0.8637\n",
      "Epoch 83/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5538 - accuracy: 0.9078 - val_loss: 1.5341 - val_accuracy: 0.9272\n",
      "Epoch 84/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5185 - accuracy: 0.9438 - val_loss: 1.5231 - val_accuracy: 0.9391\n",
      "Epoch 85/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5115 - accuracy: 0.9506 - val_loss: 1.5192 - val_accuracy: 0.9419\n",
      "Epoch 86/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5070 - accuracy: 0.9552 - val_loss: 1.5161 - val_accuracy: 0.9459\n",
      "Epoch 87/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5050 - accuracy: 0.9569 - val_loss: 1.5132 - val_accuracy: 0.9490\n",
      "Epoch 88/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5024 - accuracy: 0.9598 - val_loss: 1.5124 - val_accuracy: 0.9493\n",
      "Epoch 89/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5024 - accuracy: 0.9595 - val_loss: 1.5133 - val_accuracy: 0.9484\n",
      "Epoch 90/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5007 - accuracy: 0.9616 - val_loss: 1.5128 - val_accuracy: 0.9484\n",
      "Epoch 91/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4990 - accuracy: 0.9631 - val_loss: 1.5117 - val_accuracy: 0.9496\n",
      "Epoch 92/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4983 - accuracy: 0.9642 - val_loss: 1.5128 - val_accuracy: 0.9490\n",
      "Epoch 93/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4980 - accuracy: 0.9644 - val_loss: 1.5109 - val_accuracy: 0.9502\n",
      "Epoch 94/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4972 - accuracy: 0.9649 - val_loss: 1.5132 - val_accuracy: 0.9490\n",
      "Epoch 95/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4960 - accuracy: 0.9661 - val_loss: 1.5106 - val_accuracy: 0.9507\n",
      "Epoch 96/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4964 - accuracy: 0.9657 - val_loss: 1.5104 - val_accuracy: 0.9505\n",
      "Epoch 97/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4972 - accuracy: 0.9648 - val_loss: 1.5107 - val_accuracy: 0.9509\n",
      "Epoch 98/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4953 - accuracy: 0.9670 - val_loss: 1.5094 - val_accuracy: 0.9524\n",
      "Epoch 99/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4946 - accuracy: 0.9675 - val_loss: 1.5074 - val_accuracy: 0.9543\n",
      "Epoch 100/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4942 - accuracy: 0.9678 - val_loss: 1.5097 - val_accuracy: 0.9518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3it [12:02, 226.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.9262 - accuracy: 0.5317 - val_loss: 1.8710 - val_accuracy: 0.5880\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8114 - accuracy: 0.6482 - val_loss: 1.7748 - val_accuracy: 0.6859\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7619 - accuracy: 0.6988 - val_loss: 1.7494 - val_accuracy: 0.7113\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7161 - accuracy: 0.7453 - val_loss: 1.6844 - val_accuracy: 0.7768\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6746 - accuracy: 0.7860 - val_loss: 1.6629 - val_accuracy: 0.7993\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7204 - accuracy: 0.7419 - val_loss: 1.6769 - val_accuracy: 0.7839\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6709 - accuracy: 0.7911 - val_loss: 1.6583 - val_accuracy: 0.8020\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6546 - accuracy: 0.8066 - val_loss: 1.6517 - val_accuracy: 0.8093\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6458 - accuracy: 0.8152 - val_loss: 1.6460 - val_accuracy: 0.8150\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6392 - accuracy: 0.8219 - val_loss: 1.6383 - val_accuracy: 0.8233\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.9707 - accuracy: 0.4877 - val_loss: 1.8019 - val_accuracy: 0.6620\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7706 - accuracy: 0.6921 - val_loss: 1.7358 - val_accuracy: 0.7265\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7236 - accuracy: 0.7384 - val_loss: 1.7073 - val_accuracy: 0.7556\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6975 - accuracy: 0.7649 - val_loss: 1.6882 - val_accuracy: 0.7741\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6816 - accuracy: 0.7810 - val_loss: 1.6780 - val_accuracy: 0.7844\n",
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.9719 - accuracy: 0.4880 - val_loss: 1.8655 - val_accuracy: 0.5946\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8290 - accuracy: 0.6354 - val_loss: 1.7886 - val_accuracy: 0.6779\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7601 - accuracy: 0.7094 - val_loss: 1.7265 - val_accuracy: 0.7429\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6998 - accuracy: 0.7716 - val_loss: 1.6635 - val_accuracy: 0.8079\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6614 - accuracy: 0.8090 - val_loss: 1.6361 - val_accuracy: 0.8338\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6397 - accuracy: 0.8289 - val_loss: 1.6213 - val_accuracy: 0.8468\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6240 - accuracy: 0.8445 - val_loss: 1.6077 - val_accuracy: 0.8596\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6124 - accuracy: 0.8544 - val_loss: 1.6009 - val_accuracy: 0.8653\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6032 - accuracy: 0.8639 - val_loss: 1.5951 - val_accuracy: 0.8706\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5957 - accuracy: 0.8709 - val_loss: 1.5891 - val_accuracy: 0.8758\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5895 - accuracy: 0.8762 - val_loss: 1.5840 - val_accuracy: 0.8810\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5843 - accuracy: 0.8813 - val_loss: 1.5806 - val_accuracy: 0.8835\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5793 - accuracy: 0.8861 - val_loss: 1.5752 - val_accuracy: 0.8892\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5737 - accuracy: 0.8915 - val_loss: 1.5737 - val_accuracy: 0.8907\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5696 - accuracy: 0.8955 - val_loss: 1.5719 - val_accuracy: 0.8929\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5662 - accuracy: 0.8991 - val_loss: 1.5671 - val_accuracy: 0.8976\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5632 - accuracy: 0.9020 - val_loss: 1.5649 - val_accuracy: 0.8989\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5597 - accuracy: 0.9049 - val_loss: 1.5624 - val_accuracy: 0.9016\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5576 - accuracy: 0.9069 - val_loss: 1.5611 - val_accuracy: 0.9026\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5546 - accuracy: 0.9099 - val_loss: 1.5584 - val_accuracy: 0.9046\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5520 - accuracy: 0.9121 - val_loss: 1.5583 - val_accuracy: 0.9043\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5501 - accuracy: 0.9143 - val_loss: 1.5544 - val_accuracy: 0.9079\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5477 - accuracy: 0.9166 - val_loss: 1.5545 - val_accuracy: 0.9078\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5467 - accuracy: 0.9174 - val_loss: 1.5529 - val_accuracy: 0.9106\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5447 - accuracy: 0.9196 - val_loss: 1.5517 - val_accuracy: 0.9115\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5425 - accuracy: 0.9219 - val_loss: 1.5501 - val_accuracy: 0.9130\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5410 - accuracy: 0.9230 - val_loss: 1.5497 - val_accuracy: 0.9127\n",
      "Epoch 28/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5395 - accuracy: 0.9241 - val_loss: 1.5480 - val_accuracy: 0.9158\n",
      "Epoch 29/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5385 - accuracy: 0.9252 - val_loss: 1.5469 - val_accuracy: 0.9156\n",
      "Epoch 30/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5378 - accuracy: 0.9263 - val_loss: 1.5459 - val_accuracy: 0.9172\n",
      "Epoch 31/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5360 - accuracy: 0.9276 - val_loss: 1.5444 - val_accuracy: 0.9178\n",
      "Epoch 32/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5350 - accuracy: 0.9285 - val_loss: 1.5435 - val_accuracy: 0.9192\n",
      "Epoch 33/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5335 - accuracy: 0.9298 - val_loss: 1.5439 - val_accuracy: 0.9188\n",
      "Epoch 34/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5320 - accuracy: 0.9314 - val_loss: 1.5418 - val_accuracy: 0.9204\n",
      "Epoch 35/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5309 - accuracy: 0.9325 - val_loss: 1.5419 - val_accuracy: 0.9192\n",
      "Epoch 36/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5299 - accuracy: 0.9340 - val_loss: 1.5419 - val_accuracy: 0.9200\n",
      "Epoch 37/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5292 - accuracy: 0.9344 - val_loss: 1.5410 - val_accuracy: 0.9207\n",
      "Epoch 38/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5282 - accuracy: 0.9354 - val_loss: 1.5402 - val_accuracy: 0.9204\n",
      "Epoch 39/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5270 - accuracy: 0.9362 - val_loss: 1.5406 - val_accuracy: 0.9206\n",
      "Epoch 40/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5275 - accuracy: 0.9355 - val_loss: 1.5372 - val_accuracy: 0.9252\n",
      "Epoch 41/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5248 - accuracy: 0.9386 - val_loss: 1.5362 - val_accuracy: 0.9258\n",
      "Epoch 42/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5246 - accuracy: 0.9388 - val_loss: 1.5363 - val_accuracy: 0.9265\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5233 - accuracy: 0.9402 - val_loss: 1.5366 - val_accuracy: 0.9262\n",
      "Epoch 44/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5221 - accuracy: 0.9413 - val_loss: 1.5354 - val_accuracy: 0.9268\n",
      "Epoch 45/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5216 - accuracy: 0.9423 - val_loss: 1.5369 - val_accuracy: 0.9247\n",
      "Epoch 46/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5209 - accuracy: 0.9429 - val_loss: 1.5347 - val_accuracy: 0.9274\n",
      "Epoch 47/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5201 - accuracy: 0.9434 - val_loss: 1.5338 - val_accuracy: 0.9288\n",
      "Epoch 48/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5202 - accuracy: 0.9433 - val_loss: 1.5348 - val_accuracy: 0.9260\n",
      "Epoch 49/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5184 - accuracy: 0.9456 - val_loss: 1.5340 - val_accuracy: 0.9282\n",
      "Epoch 50/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5181 - accuracy: 0.9455 - val_loss: 1.5350 - val_accuracy: 0.9260\n",
      "Epoch 51/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5176 - accuracy: 0.9458 - val_loss: 1.5338 - val_accuracy: 0.9292\n",
      "Epoch 52/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5167 - accuracy: 0.9469 - val_loss: 1.5341 - val_accuracy: 0.9272\n",
      "Epoch 53/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5162 - accuracy: 0.9473 - val_loss: 1.5331 - val_accuracy: 0.9287\n",
      "Epoch 54/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5153 - accuracy: 0.9480 - val_loss: 1.5318 - val_accuracy: 0.9303\n",
      "Epoch 55/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5149 - accuracy: 0.9486 - val_loss: 1.5325 - val_accuracy: 0.9294\n",
      "Epoch 56/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5143 - accuracy: 0.9493 - val_loss: 1.5312 - val_accuracy: 0.9299\n",
      "Epoch 57/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5133 - accuracy: 0.9502 - val_loss: 1.5308 - val_accuracy: 0.9309\n",
      "Epoch 58/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5132 - accuracy: 0.9497 - val_loss: 1.5305 - val_accuracy: 0.9304\n",
      "Epoch 59/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5125 - accuracy: 0.9509 - val_loss: 1.5308 - val_accuracy: 0.9311\n",
      "Epoch 60/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5120 - accuracy: 0.9514 - val_loss: 1.5296 - val_accuracy: 0.9322\n",
      "Epoch 61/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5121 - accuracy: 0.9515 - val_loss: 1.5292 - val_accuracy: 0.9332\n",
      "Epoch 62/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5120 - accuracy: 0.9512 - val_loss: 1.5281 - val_accuracy: 0.9347\n",
      "Epoch 63/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5112 - accuracy: 0.9522 - val_loss: 1.5299 - val_accuracy: 0.9317\n",
      "Epoch 64/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5107 - accuracy: 0.9525 - val_loss: 1.5291 - val_accuracy: 0.9323\n",
      "Epoch 65/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5104 - accuracy: 0.9528 - val_loss: 1.5275 - val_accuracy: 0.9345\n",
      "Epoch 66/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5100 - accuracy: 0.9534 - val_loss: 1.5281 - val_accuracy: 0.9344\n",
      "Epoch 67/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5093 - accuracy: 0.9543 - val_loss: 1.5285 - val_accuracy: 0.9336\n",
      "Epoch 68/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5090 - accuracy: 0.9542 - val_loss: 1.5267 - val_accuracy: 0.9349\n",
      "Epoch 69/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5086 - accuracy: 0.9548 - val_loss: 1.5260 - val_accuracy: 0.9356\n",
      "Epoch 70/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5081 - accuracy: 0.9555 - val_loss: 1.5267 - val_accuracy: 0.9351\n",
      "Epoch 71/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5083 - accuracy: 0.9549 - val_loss: 1.5269 - val_accuracy: 0.9344\n",
      "Epoch 72/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5070 - accuracy: 0.9567 - val_loss: 1.5264 - val_accuracy: 0.9346\n",
      "Epoch 73/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5072 - accuracy: 0.9562 - val_loss: 1.5244 - val_accuracy: 0.9375\n",
      "Epoch 74/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5063 - accuracy: 0.9571 - val_loss: 1.5257 - val_accuracy: 0.9355\n",
      "Epoch 75/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5067 - accuracy: 0.9564 - val_loss: 1.5252 - val_accuracy: 0.9357\n",
      "Epoch 76/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5061 - accuracy: 0.9574 - val_loss: 1.5260 - val_accuracy: 0.9354\n",
      "Epoch 77/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5058 - accuracy: 0.9574 - val_loss: 1.5248 - val_accuracy: 0.9366\n",
      "Epoch 78/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5050 - accuracy: 0.9582 - val_loss: 1.5238 - val_accuracy: 0.9381\n",
      "Epoch 79/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5054 - accuracy: 0.9578 - val_loss: 1.5239 - val_accuracy: 0.9370\n",
      "Epoch 80/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5044 - accuracy: 0.9591 - val_loss: 1.5246 - val_accuracy: 0.9370\n",
      "Epoch 81/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5040 - accuracy: 0.9594 - val_loss: 1.5251 - val_accuracy: 0.9360\n",
      "Epoch 82/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5048 - accuracy: 0.9586 - val_loss: 1.5234 - val_accuracy: 0.9379\n",
      "Epoch 83/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5037 - accuracy: 0.9597 - val_loss: 1.5235 - val_accuracy: 0.9370\n",
      "Epoch 84/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5032 - accuracy: 0.9599 - val_loss: 1.5245 - val_accuracy: 0.9375\n",
      "Epoch 85/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5038 - accuracy: 0.9592 - val_loss: 1.5231 - val_accuracy: 0.9380\n",
      "Epoch 86/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5033 - accuracy: 0.9598 - val_loss: 1.5241 - val_accuracy: 0.9364\n",
      "Epoch 87/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5030 - accuracy: 0.9601 - val_loss: 1.5241 - val_accuracy: 0.9369\n",
      "Epoch 88/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5027 - accuracy: 0.9606 - val_loss: 1.5219 - val_accuracy: 0.9389\n",
      "Epoch 89/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5027 - accuracy: 0.9606 - val_loss: 1.5228 - val_accuracy: 0.9386\n",
      "Epoch 90/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5019 - accuracy: 0.9615 - val_loss: 1.5226 - val_accuracy: 0.9390\n",
      "Epoch 91/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5020 - accuracy: 0.9611 - val_loss: 1.5221 - val_accuracy: 0.9384\n",
      "Epoch 92/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5016 - accuracy: 0.9615 - val_loss: 1.5218 - val_accuracy: 0.9390\n",
      "Epoch 93/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5017 - accuracy: 0.9614 - val_loss: 1.5221 - val_accuracy: 0.9396\n",
      "Epoch 94/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5017 - accuracy: 0.9613 - val_loss: 1.5218 - val_accuracy: 0.9396\n",
      "Epoch 95/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5009 - accuracy: 0.9622 - val_loss: 1.5207 - val_accuracy: 0.9412\n",
      "Epoch 96/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5010 - accuracy: 0.9621 - val_loss: 1.5220 - val_accuracy: 0.9386\n",
      "Epoch 97/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5002 - accuracy: 0.9628 - val_loss: 1.5214 - val_accuracy: 0.9403\n",
      "Epoch 98/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5006 - accuracy: 0.9622 - val_loss: 1.5211 - val_accuracy: 0.9404\n",
      "Epoch 99/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5003 - accuracy: 0.9630 - val_loss: 1.5209 - val_accuracy: 0.9403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5001 - accuracy: 0.9628 - val_loss: 1.5212 - val_accuracy: 0.9400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4it [17:21, 254.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8836 - accuracy: 0.5753 - val_loss: 1.7936 - val_accuracy: 0.6680\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7528 - accuracy: 0.7085 - val_loss: 1.7142 - val_accuracy: 0.7470\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6977 - accuracy: 0.7634 - val_loss: 1.6788 - val_accuracy: 0.7817\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6760 - accuracy: 0.7845 - val_loss: 1.6693 - val_accuracy: 0.7913\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6629 - accuracy: 0.7986 - val_loss: 1.6526 - val_accuracy: 0.8077\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7003 - accuracy: 0.7608 - val_loss: 1.6695 - val_accuracy: 0.7898\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6622 - accuracy: 0.7989 - val_loss: 1.6520 - val_accuracy: 0.8087\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6521 - accuracy: 0.8086 - val_loss: 1.6472 - val_accuracy: 0.8137\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6429 - accuracy: 0.8183 - val_loss: 1.6411 - val_accuracy: 0.8199\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6384 - accuracy: 0.8227 - val_loss: 1.6377 - val_accuracy: 0.8237\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.9030 - accuracy: 0.5579 - val_loss: 1.7691 - val_accuracy: 0.6940\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7477 - accuracy: 0.7157 - val_loss: 1.7252 - val_accuracy: 0.7394\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7134 - accuracy: 0.7497 - val_loss: 1.7030 - val_accuracy: 0.7583\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6956 - accuracy: 0.7672 - val_loss: 1.6908 - val_accuracy: 0.7711\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6808 - accuracy: 0.7816 - val_loss: 1.6810 - val_accuracy: 0.7802\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.9473 - accuracy: 0.5130 - val_loss: 1.8124 - val_accuracy: 0.6521\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7773 - accuracy: 0.6880 - val_loss: 1.7411 - val_accuracy: 0.7246\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7262 - accuracy: 0.7377 - val_loss: 1.7118 - val_accuracy: 0.7516\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6988 - accuracy: 0.7652 - val_loss: 1.6926 - val_accuracy: 0.7701\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6814 - accuracy: 0.7821 - val_loss: 1.6821 - val_accuracy: 0.7807\n",
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 2.0316 - accuracy: 0.4269 - val_loss: 1.8476 - val_accuracy: 0.6159\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8028 - accuracy: 0.6591 - val_loss: 1.7610 - val_accuracy: 0.7020\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7448 - accuracy: 0.7212 - val_loss: 1.7102 - val_accuracy: 0.7579\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7018 - accuracy: 0.7676 - val_loss: 1.6784 - val_accuracy: 0.7900\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6761 - accuracy: 0.7941 - val_loss: 1.6594 - val_accuracy: 0.8093\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6592 - accuracy: 0.8105 - val_loss: 1.6436 - val_accuracy: 0.8252\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6468 - accuracy: 0.8214 - val_loss: 1.6341 - val_accuracy: 0.8330\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6365 - accuracy: 0.8313 - val_loss: 1.6261 - val_accuracy: 0.8417\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6285 - accuracy: 0.8387 - val_loss: 1.6195 - val_accuracy: 0.8475\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6212 - accuracy: 0.8458 - val_loss: 1.6136 - val_accuracy: 0.8530\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6149 - accuracy: 0.8515 - val_loss: 1.6075 - val_accuracy: 0.8591\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6086 - accuracy: 0.8576 - val_loss: 1.6021 - val_accuracy: 0.8644\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6038 - accuracy: 0.8623 - val_loss: 1.5999 - val_accuracy: 0.8651\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5996 - accuracy: 0.8663 - val_loss: 1.5968 - val_accuracy: 0.8689\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5958 - accuracy: 0.8699 - val_loss: 1.5930 - val_accuracy: 0.8729\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5922 - accuracy: 0.8733 - val_loss: 1.5889 - val_accuracy: 0.8770\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5891 - accuracy: 0.8769 - val_loss: 1.5859 - val_accuracy: 0.8799\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5855 - accuracy: 0.8799 - val_loss: 1.5863 - val_accuracy: 0.8775\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5829 - accuracy: 0.8826 - val_loss: 1.5833 - val_accuracy: 0.8812\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5805 - accuracy: 0.8847 - val_loss: 1.5806 - val_accuracy: 0.8840\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5779 - accuracy: 0.8875 - val_loss: 1.5801 - val_accuracy: 0.8839\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5768 - accuracy: 0.8881 - val_loss: 1.5760 - val_accuracy: 0.8883\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5736 - accuracy: 0.8915 - val_loss: 1.5721 - val_accuracy: 0.8930\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5711 - accuracy: 0.8937 - val_loss: 1.5736 - val_accuracy: 0.8896\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5692 - accuracy: 0.8956 - val_loss: 1.5696 - val_accuracy: 0.8956\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5674 - accuracy: 0.8973 - val_loss: 1.5689 - val_accuracy: 0.8943\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5659 - accuracy: 0.8986 - val_loss: 1.5679 - val_accuracy: 0.8964\n",
      "Epoch 28/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5637 - accuracy: 0.9009 - val_loss: 1.5685 - val_accuracy: 0.8944\n",
      "Epoch 29/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5628 - accuracy: 0.9015 - val_loss: 1.5640 - val_accuracy: 0.9000\n",
      "Epoch 30/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5609 - accuracy: 0.9034 - val_loss: 1.5637 - val_accuracy: 0.8999\n",
      "Epoch 31/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5591 - accuracy: 0.9054 - val_loss: 1.5614 - val_accuracy: 0.9027\n",
      "Epoch 32/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5576 - accuracy: 0.9070 - val_loss: 1.5608 - val_accuracy: 0.9019\n",
      "Epoch 33/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5563 - accuracy: 0.9078 - val_loss: 1.5604 - val_accuracy: 0.9028\n",
      "Epoch 34/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5552 - accuracy: 0.9090 - val_loss: 1.5596 - val_accuracy: 0.9048\n",
      "Epoch 35/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5542 - accuracy: 0.9101 - val_loss: 1.5594 - val_accuracy: 0.9037\n",
      "Epoch 36/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5534 - accuracy: 0.9108 - val_loss: 1.5578 - val_accuracy: 0.9062\n",
      "Epoch 37/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5524 - accuracy: 0.9117 - val_loss: 1.5573 - val_accuracy: 0.9062\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5516 - accuracy: 0.9128 - val_loss: 1.5559 - val_accuracy: 0.9072\n",
      "Epoch 39/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5502 - accuracy: 0.9146 - val_loss: 1.5570 - val_accuracy: 0.9061\n",
      "Epoch 40/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5494 - accuracy: 0.9148 - val_loss: 1.5565 - val_accuracy: 0.9059\n",
      "Epoch 41/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5485 - accuracy: 0.9159 - val_loss: 1.5560 - val_accuracy: 0.9070\n",
      "Epoch 42/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5481 - accuracy: 0.9160 - val_loss: 1.5557 - val_accuracy: 0.9078\n",
      "Epoch 43/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5472 - accuracy: 0.9170 - val_loss: 1.5533 - val_accuracy: 0.9098\n",
      "Epoch 44/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5458 - accuracy: 0.9184 - val_loss: 1.5541 - val_accuracy: 0.9085\n",
      "Epoch 45/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5453 - accuracy: 0.9187 - val_loss: 1.5561 - val_accuracy: 0.9070\n",
      "Epoch 46/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5447 - accuracy: 0.9196 - val_loss: 1.5544 - val_accuracy: 0.9088\n",
      "Epoch 47/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5439 - accuracy: 0.9199 - val_loss: 1.5514 - val_accuracy: 0.9106\n",
      "Epoch 48/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5431 - accuracy: 0.9210 - val_loss: 1.5518 - val_accuracy: 0.9107\n",
      "Epoch 49/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5421 - accuracy: 0.9219 - val_loss: 1.5509 - val_accuracy: 0.9117\n",
      "Epoch 50/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5414 - accuracy: 0.9225 - val_loss: 1.5516 - val_accuracy: 0.9112\n",
      "Epoch 51/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5413 - accuracy: 0.9227 - val_loss: 1.5500 - val_accuracy: 0.9126\n",
      "Epoch 52/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5404 - accuracy: 0.9235 - val_loss: 1.5505 - val_accuracy: 0.9110\n",
      "Epoch 53/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5396 - accuracy: 0.9243 - val_loss: 1.5492 - val_accuracy: 0.9130\n",
      "Epoch 54/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5392 - accuracy: 0.9247 - val_loss: 1.5492 - val_accuracy: 0.9128\n",
      "Epoch 55/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5386 - accuracy: 0.9251 - val_loss: 1.5485 - val_accuracy: 0.9139\n",
      "Epoch 56/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5376 - accuracy: 0.9262 - val_loss: 1.5487 - val_accuracy: 0.9131\n",
      "Epoch 57/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5371 - accuracy: 0.9263 - val_loss: 1.5483 - val_accuracy: 0.9135\n",
      "Epoch 58/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5362 - accuracy: 0.9276 - val_loss: 1.5481 - val_accuracy: 0.9154\n",
      "Epoch 59/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5359 - accuracy: 0.9282 - val_loss: 1.5466 - val_accuracy: 0.9160\n",
      "Epoch 60/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5351 - accuracy: 0.9290 - val_loss: 1.5481 - val_accuracy: 0.9138\n",
      "Epoch 61/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5347 - accuracy: 0.9293 - val_loss: 1.5473 - val_accuracy: 0.9147\n",
      "Epoch 62/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5346 - accuracy: 0.9295 - val_loss: 1.5475 - val_accuracy: 0.9148\n",
      "Epoch 63/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5335 - accuracy: 0.9304 - val_loss: 1.5467 - val_accuracy: 0.9152\n",
      "Epoch 64/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5336 - accuracy: 0.9303 - val_loss: 1.5460 - val_accuracy: 0.9166\n",
      "Epoch 65/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5335 - accuracy: 0.9304 - val_loss: 1.5458 - val_accuracy: 0.9162\n",
      "Epoch 66/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5328 - accuracy: 0.9313 - val_loss: 1.5467 - val_accuracy: 0.9153\n",
      "Epoch 67/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5322 - accuracy: 0.9316 - val_loss: 1.5458 - val_accuracy: 0.9164\n",
      "Epoch 68/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5321 - accuracy: 0.9316 - val_loss: 1.5457 - val_accuracy: 0.9154\n",
      "Epoch 69/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5311 - accuracy: 0.9327 - val_loss: 1.5468 - val_accuracy: 0.9146\n",
      "Epoch 70/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5313 - accuracy: 0.9326 - val_loss: 1.5446 - val_accuracy: 0.9178\n",
      "Epoch 71/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5306 - accuracy: 0.9330 - val_loss: 1.5449 - val_accuracy: 0.9171\n",
      "Epoch 72/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5303 - accuracy: 0.9335 - val_loss: 1.5440 - val_accuracy: 0.9177\n",
      "Epoch 73/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5298 - accuracy: 0.9343 - val_loss: 1.5454 - val_accuracy: 0.9172\n",
      "Epoch 74/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5295 - accuracy: 0.9343 - val_loss: 1.5440 - val_accuracy: 0.9189\n",
      "Epoch 75/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5292 - accuracy: 0.9345 - val_loss: 1.5442 - val_accuracy: 0.9174\n",
      "Epoch 76/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5289 - accuracy: 0.9346 - val_loss: 1.5439 - val_accuracy: 0.9174\n",
      "Epoch 77/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5281 - accuracy: 0.9352 - val_loss: 1.5436 - val_accuracy: 0.9185\n",
      "Epoch 78/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5280 - accuracy: 0.9354 - val_loss: 1.5426 - val_accuracy: 0.9193\n",
      "Epoch 79/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5277 - accuracy: 0.9358 - val_loss: 1.5423 - val_accuracy: 0.9195\n",
      "Epoch 80/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5275 - accuracy: 0.9362 - val_loss: 1.5430 - val_accuracy: 0.9179\n",
      "Epoch 81/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5269 - accuracy: 0.9365 - val_loss: 1.5426 - val_accuracy: 0.9193\n",
      "Epoch 82/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5269 - accuracy: 0.9369 - val_loss: 1.5426 - val_accuracy: 0.9196\n",
      "Epoch 83/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5267 - accuracy: 0.9369 - val_loss: 1.5421 - val_accuracy: 0.9203\n",
      "Epoch 84/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5264 - accuracy: 0.9371 - val_loss: 1.5421 - val_accuracy: 0.9209\n",
      "Epoch 85/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5257 - accuracy: 0.9378 - val_loss: 1.5419 - val_accuracy: 0.9204\n",
      "Epoch 86/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5256 - accuracy: 0.9380 - val_loss: 1.5425 - val_accuracy: 0.9190\n",
      "Epoch 87/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5253 - accuracy: 0.9384 - val_loss: 1.5425 - val_accuracy: 0.9190\n",
      "Epoch 88/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5255 - accuracy: 0.9382 - val_loss: 1.5416 - val_accuracy: 0.9208\n",
      "Epoch 89/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5251 - accuracy: 0.9383 - val_loss: 1.5414 - val_accuracy: 0.9200\n",
      "Epoch 90/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5247 - accuracy: 0.9391 - val_loss: 1.5405 - val_accuracy: 0.9213\n",
      "Epoch 91/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5250 - accuracy: 0.9384 - val_loss: 1.5410 - val_accuracy: 0.9212\n",
      "Epoch 92/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5239 - accuracy: 0.9398 - val_loss: 1.5408 - val_accuracy: 0.9200\n",
      "Epoch 93/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5239 - accuracy: 0.9395 - val_loss: 1.5410 - val_accuracy: 0.9214\n",
      "Epoch 94/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5240 - accuracy: 0.9394 - val_loss: 1.5401 - val_accuracy: 0.9219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5235 - accuracy: 0.9397 - val_loss: 1.5413 - val_accuracy: 0.9200\n",
      "Epoch 96/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5235 - accuracy: 0.9397 - val_loss: 1.5403 - val_accuracy: 0.9209\n",
      "Epoch 97/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5231 - accuracy: 0.9401 - val_loss: 1.5403 - val_accuracy: 0.9207\n",
      "Epoch 98/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5228 - accuracy: 0.9407 - val_loss: 1.5395 - val_accuracy: 0.9214\n",
      "Epoch 99/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5226 - accuracy: 0.9409 - val_loss: 1.5400 - val_accuracy: 0.9213\n",
      "Epoch 100/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5227 - accuracy: 0.9409 - val_loss: 1.5382 - val_accuracy: 0.9240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "5it [22:57, 278.97s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.9102 - accuracy: 0.5486 - val_loss: 1.8468 - val_accuracy: 0.6130\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8093 - accuracy: 0.6503 - val_loss: 1.7831 - val_accuracy: 0.6767\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7671 - accuracy: 0.6933 - val_loss: 1.7522 - val_accuracy: 0.7086\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7083 - accuracy: 0.7524 - val_loss: 1.6781 - val_accuracy: 0.7832\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6718 - accuracy: 0.7893 - val_loss: 1.6531 - val_accuracy: 0.8088\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6915 - accuracy: 0.7712 - val_loss: 1.6331 - val_accuracy: 0.8303\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6207 - accuracy: 0.8417 - val_loss: 1.6007 - val_accuracy: 0.8639\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5975 - accuracy: 0.8651 - val_loss: 1.5820 - val_accuracy: 0.8817\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5816 - accuracy: 0.8810 - val_loss: 1.5752 - val_accuracy: 0.8873\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5707 - accuracy: 0.8918 - val_loss: 1.5645 - val_accuracy: 0.8976\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8420 - accuracy: 0.6218 - val_loss: 1.6995 - val_accuracy: 0.7660\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6682 - accuracy: 0.7976 - val_loss: 1.6378 - val_accuracy: 0.8270\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6284 - accuracy: 0.8359 - val_loss: 1.6139 - val_accuracy: 0.8510\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6051 - accuracy: 0.8589 - val_loss: 1.5988 - val_accuracy: 0.8644\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5906 - accuracy: 0.8734 - val_loss: 1.5880 - val_accuracy: 0.8747\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 2.0017 - accuracy: 0.4568 - val_loss: 1.8466 - val_accuracy: 0.6151\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7925 - accuracy: 0.6726 - val_loss: 1.7301 - val_accuracy: 0.7387\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7062 - accuracy: 0.7610 - val_loss: 1.6782 - val_accuracy: 0.7863\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6630 - accuracy: 0.8032 - val_loss: 1.6453 - val_accuracy: 0.8191\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6368 - accuracy: 0.8295 - val_loss: 1.6259 - val_accuracy: 0.8401\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 2.0213 - accuracy: 0.4423 - val_loss: 1.8231 - val_accuracy: 0.6489\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7951 - accuracy: 0.6747 - val_loss: 1.7481 - val_accuracy: 0.7218\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7339 - accuracy: 0.7366 - val_loss: 1.7037 - val_accuracy: 0.7670\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7015 - accuracy: 0.7687 - val_loss: 1.6821 - val_accuracy: 0.7860\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6805 - accuracy: 0.7888 - val_loss: 1.6674 - val_accuracy: 0.8003\n",
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 2.1384 - accuracy: 0.3207 - val_loss: 2.0075 - val_accuracy: 0.4702\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.9717 - accuracy: 0.4974 - val_loss: 1.9196 - val_accuracy: 0.5484\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.9126 - accuracy: 0.5569 - val_loss: 1.8838 - val_accuracy: 0.5920\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8806 - accuracy: 0.5933 - val_loss: 1.8618 - val_accuracy: 0.6113\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8597 - accuracy: 0.6128 - val_loss: 1.8417 - val_accuracy: 0.6303\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8438 - accuracy: 0.6260 - val_loss: 1.8307 - val_accuracy: 0.6410\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8319 - accuracy: 0.6380 - val_loss: 1.8191 - val_accuracy: 0.6525\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8223 - accuracy: 0.6478 - val_loss: 1.8120 - val_accuracy: 0.6625\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8134 - accuracy: 0.6569 - val_loss: 1.8041 - val_accuracy: 0.6657\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8046 - accuracy: 0.6649 - val_loss: 1.7957 - val_accuracy: 0.6749\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7975 - accuracy: 0.6710 - val_loss: 1.7919 - val_accuracy: 0.6767\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7912 - accuracy: 0.6760 - val_loss: 1.7874 - val_accuracy: 0.6796\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7859 - accuracy: 0.6809 - val_loss: 1.7845 - val_accuracy: 0.6819\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7813 - accuracy: 0.6851 - val_loss: 1.7776 - val_accuracy: 0.6885\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7773 - accuracy: 0.6890 - val_loss: 1.7773 - val_accuracy: 0.6868\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7730 - accuracy: 0.6932 - val_loss: 1.7722 - val_accuracy: 0.6912\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7700 - accuracy: 0.6963 - val_loss: 1.7719 - val_accuracy: 0.6912\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7668 - accuracy: 0.6993 - val_loss: 1.7647 - val_accuracy: 0.6992\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7635 - accuracy: 0.7020 - val_loss: 1.7626 - val_accuracy: 0.7028\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7607 - accuracy: 0.7042 - val_loss: 1.7611 - val_accuracy: 0.7039\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7583 - accuracy: 0.7068 - val_loss: 1.7584 - val_accuracy: 0.7054\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7559 - accuracy: 0.7089 - val_loss: 1.7568 - val_accuracy: 0.7074\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7532 - accuracy: 0.7113 - val_loss: 1.7554 - val_accuracy: 0.7091\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7514 - accuracy: 0.7129 - val_loss: 1.7539 - val_accuracy: 0.7092\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7496 - accuracy: 0.7142 - val_loss: 1.7496 - val_accuracy: 0.7143\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7473 - accuracy: 0.7169 - val_loss: 1.7504 - val_accuracy: 0.7126\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7455 - accuracy: 0.7176 - val_loss: 1.7470 - val_accuracy: 0.7161\n",
      "Epoch 28/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7437 - accuracy: 0.7200 - val_loss: 1.7460 - val_accuracy: 0.7172\n",
      "Epoch 29/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7425 - accuracy: 0.7214 - val_loss: 1.7431 - val_accuracy: 0.7203\n",
      "Epoch 30/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7406 - accuracy: 0.7232 - val_loss: 1.7421 - val_accuracy: 0.7212\n",
      "Epoch 31/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7393 - accuracy: 0.7239 - val_loss: 1.7405 - val_accuracy: 0.7218\n",
      "Epoch 32/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7380 - accuracy: 0.7256 - val_loss: 1.7401 - val_accuracy: 0.7211\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7361 - accuracy: 0.7270 - val_loss: 1.7378 - val_accuracy: 0.7236\n",
      "Epoch 34/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7346 - accuracy: 0.7282 - val_loss: 1.7353 - val_accuracy: 0.7270\n",
      "Epoch 35/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7337 - accuracy: 0.7295 - val_loss: 1.7345 - val_accuracy: 0.7276\n",
      "Epoch 36/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7325 - accuracy: 0.7308 - val_loss: 1.7350 - val_accuracy: 0.7267\n",
      "Epoch 37/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7310 - accuracy: 0.7321 - val_loss: 1.7349 - val_accuracy: 0.7260\n",
      "Epoch 38/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7305 - accuracy: 0.7324 - val_loss: 1.7342 - val_accuracy: 0.7276\n",
      "Epoch 39/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7294 - accuracy: 0.7339 - val_loss: 1.7313 - val_accuracy: 0.7291\n",
      "Epoch 40/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7282 - accuracy: 0.7348 - val_loss: 1.7294 - val_accuracy: 0.7312\n",
      "Epoch 41/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7271 - accuracy: 0.7362 - val_loss: 1.7296 - val_accuracy: 0.7316\n",
      "Epoch 42/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7266 - accuracy: 0.7361 - val_loss: 1.7276 - val_accuracy: 0.7332\n",
      "Epoch 43/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7255 - accuracy: 0.7366 - val_loss: 1.7298 - val_accuracy: 0.7323\n",
      "Epoch 44/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7252 - accuracy: 0.7372 - val_loss: 1.7264 - val_accuracy: 0.7339\n",
      "Epoch 45/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7234 - accuracy: 0.7392 - val_loss: 1.7253 - val_accuracy: 0.7355\n",
      "Epoch 46/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7231 - accuracy: 0.7391 - val_loss: 1.7240 - val_accuracy: 0.7378\n",
      "Epoch 47/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7224 - accuracy: 0.7395 - val_loss: 1.7237 - val_accuracy: 0.7376\n",
      "Epoch 48/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7216 - accuracy: 0.7404 - val_loss: 1.7251 - val_accuracy: 0.7370\n",
      "Epoch 49/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7200 - accuracy: 0.7422 - val_loss: 1.7226 - val_accuracy: 0.7387\n",
      "Epoch 50/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7193 - accuracy: 0.7435 - val_loss: 1.7198 - val_accuracy: 0.7423\n",
      "Epoch 51/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7183 - accuracy: 0.7451 - val_loss: 1.7202 - val_accuracy: 0.7410\n",
      "Epoch 52/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7173 - accuracy: 0.7456 - val_loss: 1.7178 - val_accuracy: 0.7446\n",
      "Epoch 53/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7170 - accuracy: 0.7460 - val_loss: 1.7178 - val_accuracy: 0.7442\n",
      "Epoch 54/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7159 - accuracy: 0.7473 - val_loss: 1.7215 - val_accuracy: 0.7410\n",
      "Epoch 55/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7153 - accuracy: 0.7470 - val_loss: 1.7175 - val_accuracy: 0.7442\n",
      "Epoch 56/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7140 - accuracy: 0.7491 - val_loss: 1.7163 - val_accuracy: 0.7447\n",
      "Epoch 57/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7134 - accuracy: 0.7497 - val_loss: 1.7175 - val_accuracy: 0.7447\n",
      "Epoch 58/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7128 - accuracy: 0.7499 - val_loss: 1.7152 - val_accuracy: 0.7466\n",
      "Epoch 59/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7123 - accuracy: 0.7502 - val_loss: 1.7150 - val_accuracy: 0.7469\n",
      "Epoch 60/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7114 - accuracy: 0.7508 - val_loss: 1.7133 - val_accuracy: 0.7480\n",
      "Epoch 61/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7113 - accuracy: 0.7506 - val_loss: 1.7132 - val_accuracy: 0.7491\n",
      "Epoch 62/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7106 - accuracy: 0.7522 - val_loss: 1.7120 - val_accuracy: 0.7487\n",
      "Epoch 63/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7098 - accuracy: 0.7521 - val_loss: 1.7118 - val_accuracy: 0.7481\n",
      "Epoch 64/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7095 - accuracy: 0.7529 - val_loss: 1.7115 - val_accuracy: 0.7502\n",
      "Epoch 65/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7090 - accuracy: 0.7534 - val_loss: 1.7124 - val_accuracy: 0.7492\n",
      "Epoch 66/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7080 - accuracy: 0.7544 - val_loss: 1.7109 - val_accuracy: 0.7504\n",
      "Epoch 67/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7081 - accuracy: 0.7538 - val_loss: 1.7088 - val_accuracy: 0.7531\n",
      "Epoch 68/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7074 - accuracy: 0.7550 - val_loss: 1.7105 - val_accuracy: 0.7505\n",
      "Epoch 69/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7067 - accuracy: 0.7555 - val_loss: 1.7083 - val_accuracy: 0.7522\n",
      "Epoch 70/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7058 - accuracy: 0.7566 - val_loss: 1.7058 - val_accuracy: 0.7562\n",
      "Epoch 71/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7054 - accuracy: 0.7565 - val_loss: 1.7063 - val_accuracy: 0.7547\n",
      "Epoch 72/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7050 - accuracy: 0.7566 - val_loss: 1.7068 - val_accuracy: 0.7540\n",
      "Epoch 73/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7040 - accuracy: 0.7582 - val_loss: 1.7040 - val_accuracy: 0.7579\n",
      "Epoch 74/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7038 - accuracy: 0.7582 - val_loss: 1.7035 - val_accuracy: 0.7584\n",
      "Epoch 75/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7025 - accuracy: 0.7596 - val_loss: 1.7065 - val_accuracy: 0.7548\n",
      "Epoch 76/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7023 - accuracy: 0.7597 - val_loss: 1.7032 - val_accuracy: 0.7585\n",
      "Epoch 77/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7015 - accuracy: 0.7606 - val_loss: 1.7013 - val_accuracy: 0.7595\n",
      "Epoch 78/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7013 - accuracy: 0.7603 - val_loss: 1.7020 - val_accuracy: 0.7603\n",
      "Epoch 79/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7006 - accuracy: 0.7611 - val_loss: 1.7018 - val_accuracy: 0.7602\n",
      "Epoch 80/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7000 - accuracy: 0.7617 - val_loss: 1.7000 - val_accuracy: 0.7614\n",
      "Epoch 81/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6999 - accuracy: 0.7613 - val_loss: 1.6985 - val_accuracy: 0.7633\n",
      "Epoch 82/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6992 - accuracy: 0.7624 - val_loss: 1.7008 - val_accuracy: 0.7600\n",
      "Epoch 83/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6988 - accuracy: 0.7628 - val_loss: 1.7009 - val_accuracy: 0.7598\n",
      "Epoch 84/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6986 - accuracy: 0.7625 - val_loss: 1.6983 - val_accuracy: 0.7627\n",
      "Epoch 85/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6979 - accuracy: 0.7635 - val_loss: 1.6972 - val_accuracy: 0.7643\n",
      "Epoch 86/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6974 - accuracy: 0.7643 - val_loss: 1.6973 - val_accuracy: 0.7626\n",
      "Epoch 87/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6969 - accuracy: 0.7649 - val_loss: 1.6975 - val_accuracy: 0.7630\n",
      "Epoch 88/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6963 - accuracy: 0.7652 - val_loss: 1.6981 - val_accuracy: 0.7641\n",
      "Epoch 89/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6964 - accuracy: 0.7650 - val_loss: 1.6964 - val_accuracy: 0.7647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6957 - accuracy: 0.7650 - val_loss: 1.6965 - val_accuracy: 0.7647\n",
      "Epoch 91/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6957 - accuracy: 0.7659 - val_loss: 1.6971 - val_accuracy: 0.7632\n",
      "Epoch 92/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6949 - accuracy: 0.7666 - val_loss: 1.6947 - val_accuracy: 0.7658\n",
      "Epoch 93/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6946 - accuracy: 0.7663 - val_loss: 1.6958 - val_accuracy: 0.7656\n",
      "Epoch 94/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6944 - accuracy: 0.7666 - val_loss: 1.6952 - val_accuracy: 0.7663\n",
      "Epoch 95/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6936 - accuracy: 0.7674 - val_loss: 1.6952 - val_accuracy: 0.7661\n",
      "Epoch 96/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6934 - accuracy: 0.7674 - val_loss: 1.6938 - val_accuracy: 0.7675\n",
      "Epoch 97/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6931 - accuracy: 0.7676 - val_loss: 1.6936 - val_accuracy: 0.7666\n",
      "Epoch 98/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6930 - accuracy: 0.7680 - val_loss: 1.6948 - val_accuracy: 0.7657\n",
      "Epoch 99/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6923 - accuracy: 0.7682 - val_loss: 1.6934 - val_accuracy: 0.7667\n",
      "Epoch 100/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6921 - accuracy: 0.7685 - val_loss: 1.6938 - val_accuracy: 0.7665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "6it [28:48, 300.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.9005 - accuracy: 0.5584 - val_loss: 1.8348 - val_accuracy: 0.6241\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8053 - accuracy: 0.6552 - val_loss: 1.7853 - val_accuracy: 0.6743\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7692 - accuracy: 0.6909 - val_loss: 1.7546 - val_accuracy: 0.7060\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7184 - accuracy: 0.7429 - val_loss: 1.6880 - val_accuracy: 0.7730\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6800 - accuracy: 0.7813 - val_loss: 1.6685 - val_accuracy: 0.7928\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7104 - accuracy: 0.7512 - val_loss: 1.6713 - val_accuracy: 0.7906\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6672 - accuracy: 0.7942 - val_loss: 1.6563 - val_accuracy: 0.8045\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6552 - accuracy: 0.8057 - val_loss: 1.6488 - val_accuracy: 0.8119\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6472 - accuracy: 0.8136 - val_loss: 1.6428 - val_accuracy: 0.8183\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6412 - accuracy: 0.8200 - val_loss: 1.6376 - val_accuracy: 0.8235\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.9159 - accuracy: 0.5433 - val_loss: 1.7810 - val_accuracy: 0.6829\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7505 - accuracy: 0.7121 - val_loss: 1.7171 - val_accuracy: 0.7445\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7045 - accuracy: 0.7582 - val_loss: 1.6986 - val_accuracy: 0.7631\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6839 - accuracy: 0.7785 - val_loss: 1.6728 - val_accuracy: 0.7902\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.6677 - accuracy: 0.7951 - val_loss: 1.6647 - val_accuracy: 0.7969\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 2.0060 - accuracy: 0.4530 - val_loss: 1.8214 - val_accuracy: 0.6422\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7842 - accuracy: 0.6789 - val_loss: 1.7583 - val_accuracy: 0.7048\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7434 - accuracy: 0.7212 - val_loss: 1.7281 - val_accuracy: 0.7361\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7201 - accuracy: 0.7444 - val_loss: 1.7088 - val_accuracy: 0.7544\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7036 - accuracy: 0.7603 - val_loss: 1.6973 - val_accuracy: 0.7663\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 2.0569 - accuracy: 0.4012 - val_loss: 1.9543 - val_accuracy: 0.5028\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.9029 - accuracy: 0.5598 - val_loss: 1.8530 - val_accuracy: 0.6139\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8043 - accuracy: 0.6659 - val_loss: 1.7614 - val_accuracy: 0.7097\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7507 - accuracy: 0.7191 - val_loss: 1.7394 - val_accuracy: 0.7287\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7279 - accuracy: 0.7408 - val_loss: 1.7155 - val_accuracy: 0.7520\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 2.1748 - accuracy: 0.2769 - val_loss: 2.0798 - val_accuracy: 0.3762\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 2.0080 - accuracy: 0.4579 - val_loss: 1.9403 - val_accuracy: 0.5313\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.9193 - accuracy: 0.5495 - val_loss: 1.9068 - val_accuracy: 0.5602\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8959 - accuracy: 0.5708 - val_loss: 1.8757 - val_accuracy: 0.5932\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8661 - accuracy: 0.6007 - val_loss: 1.8610 - val_accuracy: 0.6073\n",
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 2.0893 - accuracy: 0.3769 - val_loss: 1.9893 - val_accuracy: 0.4824\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.9796 - accuracy: 0.4830 - val_loss: 1.9705 - val_accuracy: 0.4893\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.9650 - accuracy: 0.4973 - val_loss: 1.9532 - val_accuracy: 0.5116\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.9527 - accuracy: 0.5125 - val_loss: 1.9442 - val_accuracy: 0.5214\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.9444 - accuracy: 0.5204 - val_loss: 1.9381 - val_accuracy: 0.5244\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.9377 - accuracy: 0.5267 - val_loss: 1.9317 - val_accuracy: 0.5335\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.9327 - accuracy: 0.5325 - val_loss: 1.9289 - val_accuracy: 0.5345\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.9288 - accuracy: 0.5369 - val_loss: 1.9239 - val_accuracy: 0.5410\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.9243 - accuracy: 0.5425 - val_loss: 1.9199 - val_accuracy: 0.5444\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.9194 - accuracy: 0.5473 - val_loss: 1.9163 - val_accuracy: 0.5477\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.9149 - accuracy: 0.5509 - val_loss: 1.9116 - val_accuracy: 0.5540\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.9100 - accuracy: 0.5557 - val_loss: 1.9058 - val_accuracy: 0.5590\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.9048 - accuracy: 0.5609 - val_loss: 1.9015 - val_accuracy: 0.5641\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8998 - accuracy: 0.5656 - val_loss: 1.8978 - val_accuracy: 0.5671\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8951 - accuracy: 0.5698 - val_loss: 1.8923 - val_accuracy: 0.5732\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8889 - accuracy: 0.5763 - val_loss: 1.8826 - val_accuracy: 0.5817\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8786 - accuracy: 0.5876 - val_loss: 1.8672 - val_accuracy: 0.5990\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8709 - accuracy: 0.5940 - val_loss: 1.8648 - val_accuracy: 0.6000\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8652 - accuracy: 0.5998 - val_loss: 1.8585 - val_accuracy: 0.6065\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8597 - accuracy: 0.6050 - val_loss: 1.8489 - val_accuracy: 0.6153\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8559 - accuracy: 0.6079 - val_loss: 1.8485 - val_accuracy: 0.6163\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8520 - accuracy: 0.6122 - val_loss: 1.8426 - val_accuracy: 0.6211\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8483 - accuracy: 0.6149 - val_loss: 1.8409 - val_accuracy: 0.6215\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8447 - accuracy: 0.6187 - val_loss: 1.8372 - val_accuracy: 0.6260\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8415 - accuracy: 0.6219 - val_loss: 1.8348 - val_accuracy: 0.6281\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8394 - accuracy: 0.6237 - val_loss: 1.8335 - val_accuracy: 0.6286\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8361 - accuracy: 0.6262 - val_loss: 1.8294 - val_accuracy: 0.6342\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8331 - accuracy: 0.6292 - val_loss: 1.8259 - val_accuracy: 0.6363\n",
      "Epoch 29/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8296 - accuracy: 0.6329 - val_loss: 1.8221 - val_accuracy: 0.6403\n",
      "Epoch 30/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8242 - accuracy: 0.6378 - val_loss: 1.8105 - val_accuracy: 0.6515\n",
      "Epoch 31/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8181 - accuracy: 0.6447 - val_loss: 1.8076 - val_accuracy: 0.6557\n",
      "Epoch 32/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8111 - accuracy: 0.6518 - val_loss: 1.8010 - val_accuracy: 0.6616\n",
      "Epoch 33/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8068 - accuracy: 0.6558 - val_loss: 1.7967 - val_accuracy: 0.6665\n",
      "Epoch 34/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.8028 - accuracy: 0.6598 - val_loss: 1.7978 - val_accuracy: 0.6659\n",
      "Epoch 35/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7988 - accuracy: 0.6639 - val_loss: 1.7882 - val_accuracy: 0.6733\n",
      "Epoch 36/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7951 - accuracy: 0.6664 - val_loss: 1.7838 - val_accuracy: 0.6777\n",
      "Epoch 37/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7916 - accuracy: 0.6698 - val_loss: 1.7816 - val_accuracy: 0.6802\n",
      "Epoch 38/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7887 - accuracy: 0.6723 - val_loss: 1.7826 - val_accuracy: 0.6785\n",
      "Epoch 39/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7865 - accuracy: 0.6750 - val_loss: 1.7790 - val_accuracy: 0.6822\n",
      "Epoch 40/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7836 - accuracy: 0.6775 - val_loss: 1.7770 - val_accuracy: 0.6844\n",
      "Epoch 41/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7815 - accuracy: 0.6796 - val_loss: 1.7749 - val_accuracy: 0.6861\n",
      "Epoch 42/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7800 - accuracy: 0.6814 - val_loss: 1.7759 - val_accuracy: 0.6843\n",
      "Epoch 43/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7778 - accuracy: 0.6827 - val_loss: 1.7721 - val_accuracy: 0.6870\n",
      "Epoch 44/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7763 - accuracy: 0.6842 - val_loss: 1.7691 - val_accuracy: 0.6909\n",
      "Epoch 45/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7748 - accuracy: 0.6864 - val_loss: 1.7676 - val_accuracy: 0.6951\n",
      "Epoch 46/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7732 - accuracy: 0.6896 - val_loss: 1.7675 - val_accuracy: 0.6961\n",
      "Epoch 47/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7722 - accuracy: 0.6911 - val_loss: 1.7656 - val_accuracy: 0.6978\n",
      "Epoch 48/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7703 - accuracy: 0.6929 - val_loss: 1.7635 - val_accuracy: 0.6991\n",
      "Epoch 49/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7683 - accuracy: 0.6946 - val_loss: 1.7652 - val_accuracy: 0.6983\n",
      "Epoch 50/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7676 - accuracy: 0.6955 - val_loss: 1.7606 - val_accuracy: 0.7034\n",
      "Epoch 51/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7660 - accuracy: 0.6976 - val_loss: 1.7598 - val_accuracy: 0.7029\n",
      "Epoch 52/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7649 - accuracy: 0.6985 - val_loss: 1.7572 - val_accuracy: 0.7060\n",
      "Epoch 53/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7638 - accuracy: 0.6996 - val_loss: 1.7552 - val_accuracy: 0.7078\n",
      "Epoch 54/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7625 - accuracy: 0.7006 - val_loss: 1.7549 - val_accuracy: 0.7091\n",
      "Epoch 55/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7613 - accuracy: 0.7019 - val_loss: 1.7545 - val_accuracy: 0.7095\n",
      "Epoch 56/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7603 - accuracy: 0.7034 - val_loss: 1.7542 - val_accuracy: 0.7097\n",
      "Epoch 57/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7590 - accuracy: 0.7049 - val_loss: 1.7513 - val_accuracy: 0.7127\n",
      "Epoch 58/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7586 - accuracy: 0.7047 - val_loss: 1.7518 - val_accuracy: 0.7117\n",
      "Epoch 59/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7576 - accuracy: 0.7056 - val_loss: 1.7544 - val_accuracy: 0.7093\n",
      "Epoch 60/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7567 - accuracy: 0.7068 - val_loss: 1.7506 - val_accuracy: 0.7126\n",
      "Epoch 61/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7560 - accuracy: 0.7070 - val_loss: 1.7487 - val_accuracy: 0.7152\n",
      "Epoch 62/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7553 - accuracy: 0.7074 - val_loss: 1.7492 - val_accuracy: 0.7142\n",
      "Epoch 63/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7540 - accuracy: 0.7095 - val_loss: 1.7486 - val_accuracy: 0.7148\n",
      "Epoch 64/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7534 - accuracy: 0.7097 - val_loss: 1.7477 - val_accuracy: 0.7145\n",
      "Epoch 65/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7529 - accuracy: 0.7103 - val_loss: 1.7460 - val_accuracy: 0.7167\n",
      "Epoch 66/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7521 - accuracy: 0.7109 - val_loss: 1.7461 - val_accuracy: 0.7171\n",
      "Epoch 67/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7516 - accuracy: 0.7114 - val_loss: 1.7442 - val_accuracy: 0.7190\n",
      "Epoch 68/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7500 - accuracy: 0.7131 - val_loss: 1.7438 - val_accuracy: 0.7195\n",
      "Epoch 69/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7498 - accuracy: 0.7134 - val_loss: 1.7420 - val_accuracy: 0.7207\n",
      "Epoch 70/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7490 - accuracy: 0.7143 - val_loss: 1.7439 - val_accuracy: 0.7188\n",
      "Epoch 71/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7484 - accuracy: 0.7151 - val_loss: 1.7436 - val_accuracy: 0.7190\n",
      "Epoch 72/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7486 - accuracy: 0.7146 - val_loss: 1.7399 - val_accuracy: 0.7227\n",
      "Epoch 73/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7472 - accuracy: 0.7162 - val_loss: 1.7453 - val_accuracy: 0.7187\n",
      "Epoch 74/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7469 - accuracy: 0.7163 - val_loss: 1.7395 - val_accuracy: 0.7235\n",
      "Epoch 75/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7467 - accuracy: 0.7164 - val_loss: 1.7394 - val_accuracy: 0.7239\n",
      "Epoch 76/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7458 - accuracy: 0.7171 - val_loss: 1.7407 - val_accuracy: 0.7225\n",
      "Epoch 77/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7450 - accuracy: 0.7180 - val_loss: 1.7418 - val_accuracy: 0.7205\n",
      "Epoch 78/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7446 - accuracy: 0.7183 - val_loss: 1.7362 - val_accuracy: 0.7270\n",
      "Epoch 79/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7451 - accuracy: 0.7175 - val_loss: 1.7378 - val_accuracy: 0.7249\n",
      "Epoch 80/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7437 - accuracy: 0.7189 - val_loss: 1.7366 - val_accuracy: 0.7256\n",
      "Epoch 81/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7431 - accuracy: 0.7198 - val_loss: 1.7360 - val_accuracy: 0.7283\n",
      "Epoch 82/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7423 - accuracy: 0.7203 - val_loss: 1.7367 - val_accuracy: 0.7255\n",
      "Epoch 83/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7425 - accuracy: 0.7204 - val_loss: 1.7358 - val_accuracy: 0.7267\n",
      "Epoch 84/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7421 - accuracy: 0.7206 - val_loss: 1.7398 - val_accuracy: 0.7232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7412 - accuracy: 0.7217 - val_loss: 1.7357 - val_accuracy: 0.7269\n",
      "Epoch 86/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7402 - accuracy: 0.7223 - val_loss: 1.7381 - val_accuracy: 0.7243\n",
      "Epoch 87/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7391 - accuracy: 0.7240 - val_loss: 1.7341 - val_accuracy: 0.7294\n",
      "Epoch 88/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7386 - accuracy: 0.7244 - val_loss: 1.7356 - val_accuracy: 0.7264\n",
      "Epoch 89/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7379 - accuracy: 0.7248 - val_loss: 1.7349 - val_accuracy: 0.7263\n",
      "Epoch 90/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7380 - accuracy: 0.7246 - val_loss: 1.7327 - val_accuracy: 0.7296\n",
      "Epoch 91/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7373 - accuracy: 0.7252 - val_loss: 1.7311 - val_accuracy: 0.7309\n",
      "Epoch 92/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7372 - accuracy: 0.7253 - val_loss: 1.7366 - val_accuracy: 0.7259\n",
      "Epoch 93/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7365 - accuracy: 0.7265 - val_loss: 1.7300 - val_accuracy: 0.7332\n",
      "Epoch 94/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7358 - accuracy: 0.7269 - val_loss: 1.7297 - val_accuracy: 0.7328\n",
      "Epoch 95/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7349 - accuracy: 0.7275 - val_loss: 1.7314 - val_accuracy: 0.7296\n",
      "Epoch 96/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7346 - accuracy: 0.7280 - val_loss: 1.7304 - val_accuracy: 0.7319\n",
      "Epoch 97/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7337 - accuracy: 0.7286 - val_loss: 1.7282 - val_accuracy: 0.7341\n",
      "Epoch 98/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7330 - accuracy: 0.7298 - val_loss: 1.7292 - val_accuracy: 0.7336\n",
      "Epoch 99/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7320 - accuracy: 0.7306 - val_loss: 1.7261 - val_accuracy: 0.7367\n",
      "Epoch 100/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7318 - accuracy: 0.7305 - val_loss: 1.7278 - val_accuracy: 0.7341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "7it [34:53, 299.10s/it]\u001b[A\n",
      " 33%|      | 1/3 [34:59<1:09:59, 2099.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7309 - accuracy: 0.7319 - val_loss: 1.7260 - val_accuracy: 0.7357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7304 - accuracy: 0.7320 - val_loss: 1.7274 - val_accuracy: 0.7339\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7295 - accuracy: 0.7327 - val_loss: 1.7248 - val_accuracy: 0.7380\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7290 - accuracy: 0.7327 - val_loss: 1.7270 - val_accuracy: 0.7354\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7281 - accuracy: 0.7341 - val_loss: 1.7246 - val_accuracy: 0.7379\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7277 - accuracy: 0.7344 - val_loss: 1.7254 - val_accuracy: 0.7366\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7275 - accuracy: 0.7344 - val_loss: 1.7250 - val_accuracy: 0.7368\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7264 - accuracy: 0.7359 - val_loss: 1.7253 - val_accuracy: 0.7374\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7255 - accuracy: 0.7365 - val_loss: 1.7227 - val_accuracy: 0.7389\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7257 - accuracy: 0.7363 - val_loss: 1.7224 - val_accuracy: 0.7392\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7246 - accuracy: 0.7379 - val_loss: 1.7220 - val_accuracy: 0.7400\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7239 - accuracy: 0.7384 - val_loss: 1.7214 - val_accuracy: 0.7407\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7238 - accuracy: 0.7382 - val_loss: 1.7216 - val_accuracy: 0.7405\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7241 - accuracy: 0.7379 - val_loss: 1.7214 - val_accuracy: 0.7406\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7231 - accuracy: 0.7388 - val_loss: 1.7205 - val_accuracy: 0.7414\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7226 - accuracy: 0.7395 - val_loss: 1.7219 - val_accuracy: 0.7401\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7225 - accuracy: 0.7392 - val_loss: 1.7193 - val_accuracy: 0.7427\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7223 - accuracy: 0.7399 - val_loss: 1.7217 - val_accuracy: 0.7400\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7218 - accuracy: 0.7403 - val_loss: 1.7195 - val_accuracy: 0.7423\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7212 - accuracy: 0.7408 - val_loss: 1.7180 - val_accuracy: 0.7442\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7209 - accuracy: 0.7409 - val_loss: 1.7197 - val_accuracy: 0.7414\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7207 - accuracy: 0.7415 - val_loss: 1.7168 - val_accuracy: 0.7453\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7200 - accuracy: 0.7419 - val_loss: 1.7175 - val_accuracy: 0.7453\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7196 - accuracy: 0.7426 - val_loss: 1.7181 - val_accuracy: 0.7440\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7199 - accuracy: 0.7422 - val_loss: 1.7173 - val_accuracy: 0.7454\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7199 - accuracy: 0.7424 - val_loss: 1.7204 - val_accuracy: 0.7402\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7193 - accuracy: 0.7428 - val_loss: 1.7171 - val_accuracy: 0.7445\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7191 - accuracy: 0.7430 - val_loss: 1.7172 - val_accuracy: 0.7441\n",
      "Epoch 28/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7189 - accuracy: 0.7431 - val_loss: 1.7173 - val_accuracy: 0.7443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [01:19, 79.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7306 - accuracy: 0.7316 - val_loss: 1.7274 - val_accuracy: 0.7354\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7296 - accuracy: 0.7334 - val_loss: 1.7272 - val_accuracy: 0.7358\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7293 - accuracy: 0.7333 - val_loss: 1.7267 - val_accuracy: 0.7347\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7286 - accuracy: 0.7337 - val_loss: 1.7235 - val_accuracy: 0.7390\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7275 - accuracy: 0.7347 - val_loss: 1.7235 - val_accuracy: 0.7378\n",
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7271 - accuracy: 0.7351 - val_loss: 1.7263 - val_accuracy: 0.7352\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7263 - accuracy: 0.7359 - val_loss: 1.7275 - val_accuracy: 0.7346\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7258 - accuracy: 0.7363 - val_loss: 1.7220 - val_accuracy: 0.7406\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7256 - accuracy: 0.7364 - val_loss: 1.7231 - val_accuracy: 0.7390\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7248 - accuracy: 0.7373 - val_loss: 1.7217 - val_accuracy: 0.7395\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7244 - accuracy: 0.7379 - val_loss: 1.7210 - val_accuracy: 0.7406\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7238 - accuracy: 0.7383 - val_loss: 1.7203 - val_accuracy: 0.7425\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7236 - accuracy: 0.7387 - val_loss: 1.7198 - val_accuracy: 0.7432\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7234 - accuracy: 0.7388 - val_loss: 1.7222 - val_accuracy: 0.7399\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7225 - accuracy: 0.7396 - val_loss: 1.7192 - val_accuracy: 0.7427\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7221 - accuracy: 0.7397 - val_loss: 1.7186 - val_accuracy: 0.7434\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7222 - accuracy: 0.7399 - val_loss: 1.7191 - val_accuracy: 0.7426\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7219 - accuracy: 0.7403 - val_loss: 1.7178 - val_accuracy: 0.7440\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7213 - accuracy: 0.7407 - val_loss: 1.7215 - val_accuracy: 0.7409\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7216 - accuracy: 0.7405 - val_loss: 1.7184 - val_accuracy: 0.7432\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7203 - accuracy: 0.7418 - val_loss: 1.7193 - val_accuracy: 0.7429\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7206 - accuracy: 0.7418 - val_loss: 1.7166 - val_accuracy: 0.7459\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7201 - accuracy: 0.7420 - val_loss: 1.7169 - val_accuracy: 0.7456\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7198 - accuracy: 0.7421 - val_loss: 1.7163 - val_accuracy: 0.7460\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7200 - accuracy: 0.7417 - val_loss: 1.7159 - val_accuracy: 0.7463\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7196 - accuracy: 0.7422 - val_loss: 1.7180 - val_accuracy: 0.7430\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7197 - accuracy: 0.7419 - val_loss: 1.7158 - val_accuracy: 0.7463\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7188 - accuracy: 0.7435 - val_loss: 1.7163 - val_accuracy: 0.7463\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7183 - accuracy: 0.7441 - val_loss: 1.7165 - val_accuracy: 0.7450\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7184 - accuracy: 0.7438 - val_loss: 1.7163 - val_accuracy: 0.7458\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7179 - accuracy: 0.7444 - val_loss: 1.7158 - val_accuracy: 0.7462\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7185 - accuracy: 0.7434 - val_loss: 1.7165 - val_accuracy: 0.7466\n",
      "Epoch 28/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7180 - accuracy: 0.7440 - val_loss: 1.7161 - val_accuracy: 0.7444\n",
      "Epoch 29/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7180 - accuracy: 0.7439 - val_loss: 1.7151 - val_accuracy: 0.7460\n",
      "Epoch 30/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7174 - accuracy: 0.7450 - val_loss: 1.7155 - val_accuracy: 0.7456\n",
      "Epoch 31/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7171 - accuracy: 0.7444 - val_loss: 1.7152 - val_accuracy: 0.7455\n",
      "Epoch 32/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7172 - accuracy: 0.7449 - val_loss: 1.7153 - val_accuracy: 0.7457\n",
      "Epoch 33/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7167 - accuracy: 0.7449 - val_loss: 1.7143 - val_accuracy: 0.7472\n",
      "Epoch 34/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7169 - accuracy: 0.7454 - val_loss: 1.7151 - val_accuracy: 0.7474\n",
      "Epoch 35/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7164 - accuracy: 0.7455 - val_loss: 1.7138 - val_accuracy: 0.7471\n",
      "Epoch 36/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7163 - accuracy: 0.7456 - val_loss: 1.7141 - val_accuracy: 0.7481\n",
      "Epoch 37/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7164 - accuracy: 0.7451 - val_loss: 1.7128 - val_accuracy: 0.7496\n",
      "Epoch 38/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7160 - accuracy: 0.7454 - val_loss: 1.7143 - val_accuracy: 0.7476\n",
      "Epoch 39/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7159 - accuracy: 0.7459 - val_loss: 1.7131 - val_accuracy: 0.7486\n",
      "Epoch 40/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7155 - accuracy: 0.7463 - val_loss: 1.7136 - val_accuracy: 0.7480\n",
      "Epoch 41/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7157 - accuracy: 0.7458 - val_loss: 1.7137 - val_accuracy: 0.7469\n",
      "Epoch 42/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7149 - accuracy: 0.7472 - val_loss: 1.7124 - val_accuracy: 0.7489\n",
      "Epoch 43/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7153 - accuracy: 0.7465 - val_loss: 1.7124 - val_accuracy: 0.7494\n",
      "Epoch 44/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7148 - accuracy: 0.7471 - val_loss: 1.7125 - val_accuracy: 0.7493\n",
      "Epoch 45/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7142 - accuracy: 0.7476 - val_loss: 1.7122 - val_accuracy: 0.7496\n",
      "Epoch 46/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7146 - accuracy: 0.7470 - val_loss: 1.7134 - val_accuracy: 0.7475\n",
      "Epoch 47/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7141 - accuracy: 0.7473 - val_loss: 1.7126 - val_accuracy: 0.7484\n",
      "Epoch 48/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7140 - accuracy: 0.7483 - val_loss: 1.7118 - val_accuracy: 0.7497\n",
      "Epoch 49/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7143 - accuracy: 0.7476 - val_loss: 1.7124 - val_accuracy: 0.7489\n",
      "Epoch 50/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7140 - accuracy: 0.7475 - val_loss: 1.7135 - val_accuracy: 0.7480\n",
      "Epoch 51/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7135 - accuracy: 0.7483 - val_loss: 1.7123 - val_accuracy: 0.7493\n",
      "Epoch 52/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7133 - accuracy: 0.7484 - val_loss: 1.7117 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7135 - accuracy: 0.7478 - val_loss: 1.7114 - val_accuracy: 0.7494\n",
      "Epoch 54/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7136 - accuracy: 0.7481 - val_loss: 1.7126 - val_accuracy: 0.7491\n",
      "Epoch 55/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7132 - accuracy: 0.7487 - val_loss: 1.7108 - val_accuracy: 0.7511\n",
      "Epoch 56/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7126 - accuracy: 0.7493 - val_loss: 1.7110 - val_accuracy: 0.7513\n",
      "Epoch 57/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7122 - accuracy: 0.7496 - val_loss: 1.7112 - val_accuracy: 0.7508\n",
      "Epoch 58/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7126 - accuracy: 0.7492 - val_loss: 1.7123 - val_accuracy: 0.7494\n",
      "Epoch 59/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7130 - accuracy: 0.7487 - val_loss: 1.7119 - val_accuracy: 0.7497\n",
      "Epoch 60/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7124 - accuracy: 0.7491 - val_loss: 1.7104 - val_accuracy: 0.7499\n",
      "Epoch 61/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7121 - accuracy: 0.7499 - val_loss: 1.7114 - val_accuracy: 0.7496\n",
      "Epoch 62/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7124 - accuracy: 0.7494 - val_loss: 1.7122 - val_accuracy: 0.7485\n",
      "Epoch 63/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7130 - accuracy: 0.7487 - val_loss: 1.7121 - val_accuracy: 0.7496\n",
      "Epoch 64/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7123 - accuracy: 0.7496 - val_loss: 1.7092 - val_accuracy: 0.7530\n",
      "Epoch 65/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7120 - accuracy: 0.7498 - val_loss: 1.7094 - val_accuracy: 0.7521\n",
      "Epoch 66/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7115 - accuracy: 0.7502 - val_loss: 1.7101 - val_accuracy: 0.7507\n",
      "Epoch 67/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7113 - accuracy: 0.7504 - val_loss: 1.7095 - val_accuracy: 0.7523\n",
      "Epoch 68/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7115 - accuracy: 0.7504 - val_loss: 1.7095 - val_accuracy: 0.7518\n",
      "Epoch 69/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7108 - accuracy: 0.7507 - val_loss: 1.7117 - val_accuracy: 0.7491\n",
      "Epoch 70/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7113 - accuracy: 0.7506 - val_loss: 1.7084 - val_accuracy: 0.7525\n",
      "Epoch 71/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7107 - accuracy: 0.7510 - val_loss: 1.7096 - val_accuracy: 0.7512\n",
      "Epoch 72/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7115 - accuracy: 0.7500 - val_loss: 1.7085 - val_accuracy: 0.7531\n",
      "Epoch 73/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7106 - accuracy: 0.7513 - val_loss: 1.7107 - val_accuracy: 0.7510\n",
      "Epoch 74/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7108 - accuracy: 0.7513 - val_loss: 1.7095 - val_accuracy: 0.7511\n",
      "Epoch 75/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7103 - accuracy: 0.7512 - val_loss: 1.7080 - val_accuracy: 0.7528\n",
      "Epoch 76/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7102 - accuracy: 0.7512 - val_loss: 1.7092 - val_accuracy: 0.7516\n",
      "Epoch 77/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7105 - accuracy: 0.7512 - val_loss: 1.7089 - val_accuracy: 0.7534\n",
      "Epoch 78/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7101 - accuracy: 0.7517 - val_loss: 1.7084 - val_accuracy: 0.7527\n",
      "Epoch 79/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7099 - accuracy: 0.7517 - val_loss: 1.7079 - val_accuracy: 0.7530\n",
      "Epoch 80/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7095 - accuracy: 0.7524 - val_loss: 1.7092 - val_accuracy: 0.7532\n",
      "Epoch 81/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7099 - accuracy: 0.7516 - val_loss: 1.7079 - val_accuracy: 0.7534\n",
      "Epoch 82/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7092 - accuracy: 0.7527 - val_loss: 1.7090 - val_accuracy: 0.7528\n",
      "Epoch 83/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7092 - accuracy: 0.7523 - val_loss: 1.7082 - val_accuracy: 0.7529\n",
      "Epoch 84/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7084 - accuracy: 0.7533 - val_loss: 1.7087 - val_accuracy: 0.7520\n",
      "Epoch 85/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7090 - accuracy: 0.7528 - val_loss: 1.7085 - val_accuracy: 0.7524\n",
      "Epoch 86/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7084 - accuracy: 0.7533 - val_loss: 1.7075 - val_accuracy: 0.7528\n",
      "Epoch 87/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7083 - accuracy: 0.7534 - val_loss: 1.7086 - val_accuracy: 0.7519\n",
      "Epoch 88/100\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 1.7084 - accuracy: 0.7531 - val_loss: 1.7071 - val_accuracy: 0.7547\n",
      "Epoch 89/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7084 - accuracy: 0.7532 - val_loss: 1.7075 - val_accuracy: 0.7531\n",
      "Epoch 90/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7079 - accuracy: 0.7539 - val_loss: 1.7081 - val_accuracy: 0.7529\n",
      "Epoch 91/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7078 - accuracy: 0.7541 - val_loss: 1.7072 - val_accuracy: 0.7541\n",
      "Epoch 92/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7077 - accuracy: 0.7536 - val_loss: 1.7071 - val_accuracy: 0.7546\n",
      "Epoch 93/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7076 - accuracy: 0.7538 - val_loss: 1.7071 - val_accuracy: 0.7538\n",
      "Epoch 94/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7072 - accuracy: 0.7545 - val_loss: 1.7070 - val_accuracy: 0.7546\n",
      "Epoch 95/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7078 - accuracy: 0.7538 - val_loss: 1.7075 - val_accuracy: 0.7527\n",
      "Epoch 96/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7068 - accuracy: 0.7548 - val_loss: 1.7063 - val_accuracy: 0.7543\n",
      "Epoch 97/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7072 - accuracy: 0.7546 - val_loss: 1.7073 - val_accuracy: 0.7534\n",
      "Epoch 98/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7073 - accuracy: 0.7543 - val_loss: 1.7077 - val_accuracy: 0.7532\n",
      "Epoch 99/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7071 - accuracy: 0.7541 - val_loss: 1.7079 - val_accuracy: 0.7518\n",
      "Epoch 100/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7071 - accuracy: 0.7545 - val_loss: 1.7125 - val_accuracy: 0.7481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [06:11, 143.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7304 - accuracy: 0.7321 - val_loss: 1.7258 - val_accuracy: 0.7354\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7291 - accuracy: 0.7331 - val_loss: 1.7249 - val_accuracy: 0.7379\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7288 - accuracy: 0.7333 - val_loss: 1.7242 - val_accuracy: 0.7381\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7283 - accuracy: 0.7339 - val_loss: 1.7251 - val_accuracy: 0.7370\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7276 - accuracy: 0.7348 - val_loss: 1.7236 - val_accuracy: 0.7382\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7270 - accuracy: 0.7352 - val_loss: 1.7224 - val_accuracy: 0.7403\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7265 - accuracy: 0.7358 - val_loss: 1.7254 - val_accuracy: 0.7367\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7258 - accuracy: 0.7360 - val_loss: 1.7246 - val_accuracy: 0.7379\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7258 - accuracy: 0.7362 - val_loss: 1.7242 - val_accuracy: 0.7389\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7248 - accuracy: 0.7373 - val_loss: 1.7213 - val_accuracy: 0.7412\n",
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7247 - accuracy: 0.7376 - val_loss: 1.7210 - val_accuracy: 0.7416\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7238 - accuracy: 0.7386 - val_loss: 1.7225 - val_accuracy: 0.7399\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7237 - accuracy: 0.7386 - val_loss: 1.7208 - val_accuracy: 0.7420\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7231 - accuracy: 0.7389 - val_loss: 1.7188 - val_accuracy: 0.7427\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7222 - accuracy: 0.7397 - val_loss: 1.7204 - val_accuracy: 0.7421\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7223 - accuracy: 0.7398 - val_loss: 1.7203 - val_accuracy: 0.7416\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7221 - accuracy: 0.7401 - val_loss: 1.7244 - val_accuracy: 0.7380\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7214 - accuracy: 0.7409 - val_loss: 1.7193 - val_accuracy: 0.7427\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7211 - accuracy: 0.7411 - val_loss: 1.7173 - val_accuracy: 0.7437\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7207 - accuracy: 0.7414 - val_loss: 1.7196 - val_accuracy: 0.7416\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7204 - accuracy: 0.7420 - val_loss: 1.7169 - val_accuracy: 0.7444\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7205 - accuracy: 0.7415 - val_loss: 1.7183 - val_accuracy: 0.7432\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7200 - accuracy: 0.7421 - val_loss: 1.7175 - val_accuracy: 0.7449\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7197 - accuracy: 0.7426 - val_loss: 1.7171 - val_accuracy: 0.7455\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7198 - accuracy: 0.7422 - val_loss: 1.7174 - val_accuracy: 0.7443\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7193 - accuracy: 0.7427 - val_loss: 1.7160 - val_accuracy: 0.7453\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7184 - accuracy: 0.7439 - val_loss: 1.7187 - val_accuracy: 0.7431\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7189 - accuracy: 0.7428 - val_loss: 1.7173 - val_accuracy: 0.7451\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7182 - accuracy: 0.7438 - val_loss: 1.7157 - val_accuracy: 0.7467\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7186 - accuracy: 0.7435 - val_loss: 1.7154 - val_accuracy: 0.7468\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7177 - accuracy: 0.7442 - val_loss: 1.7162 - val_accuracy: 0.7454\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7181 - accuracy: 0.7439 - val_loss: 1.7161 - val_accuracy: 0.7457\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7181 - accuracy: 0.7438 - val_loss: 1.7153 - val_accuracy: 0.7464\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7178 - accuracy: 0.7441 - val_loss: 1.7142 - val_accuracy: 0.7482\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7175 - accuracy: 0.7442 - val_loss: 1.7153 - val_accuracy: 0.7465\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7173 - accuracy: 0.7444 - val_loss: 1.7153 - val_accuracy: 0.7456\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7169 - accuracy: 0.7454 - val_loss: 1.7157 - val_accuracy: 0.7457\n",
      "Epoch 28/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7164 - accuracy: 0.7455 - val_loss: 1.7151 - val_accuracy: 0.7467\n",
      "Epoch 29/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7168 - accuracy: 0.7451 - val_loss: 1.7149 - val_accuracy: 0.7462\n",
      "Epoch 30/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7166 - accuracy: 0.7451 - val_loss: 1.7154 - val_accuracy: 0.7452\n",
      "Epoch 31/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7162 - accuracy: 0.7460 - val_loss: 1.7145 - val_accuracy: 0.7469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3it [08:08, 135.12s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7302 - accuracy: 0.7322 - val_loss: 1.7270 - val_accuracy: 0.7350\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7293 - accuracy: 0.7329 - val_loss: 1.7268 - val_accuracy: 0.7342\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7292 - accuracy: 0.7328 - val_loss: 1.7277 - val_accuracy: 0.7343\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7286 - accuracy: 0.7339 - val_loss: 1.7270 - val_accuracy: 0.7351\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7287 - accuracy: 0.7335 - val_loss: 1.7243 - val_accuracy: 0.7373\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7271 - accuracy: 0.7349 - val_loss: 1.7270 - val_accuracy: 0.7350\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7265 - accuracy: 0.7358 - val_loss: 1.7244 - val_accuracy: 0.7382\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7259 - accuracy: 0.7363 - val_loss: 1.7225 - val_accuracy: 0.7399\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7255 - accuracy: 0.7364 - val_loss: 1.7220 - val_accuracy: 0.7397\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7251 - accuracy: 0.7370 - val_loss: 1.7212 - val_accuracy: 0.7417\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7244 - accuracy: 0.7380 - val_loss: 1.7205 - val_accuracy: 0.7423\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7236 - accuracy: 0.7389 - val_loss: 1.7233 - val_accuracy: 0.7383\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7230 - accuracy: 0.7396 - val_loss: 1.7208 - val_accuracy: 0.7408\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7234 - accuracy: 0.7386 - val_loss: 1.7199 - val_accuracy: 0.7422\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7225 - accuracy: 0.7396 - val_loss: 1.7194 - val_accuracy: 0.7432\n",
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7226 - accuracy: 0.7395 - val_loss: 1.7203 - val_accuracy: 0.7417\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7223 - accuracy: 0.7400 - val_loss: 1.7205 - val_accuracy: 0.7415\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7219 - accuracy: 0.7401 - val_loss: 1.7186 - val_accuracy: 0.7442\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7213 - accuracy: 0.7408 - val_loss: 1.7188 - val_accuracy: 0.7430\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7212 - accuracy: 0.7409 - val_loss: 1.7205 - val_accuracy: 0.7419\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7211 - accuracy: 0.7409 - val_loss: 1.7194 - val_accuracy: 0.7429\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7201 - accuracy: 0.7418 - val_loss: 1.7177 - val_accuracy: 0.7434\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7203 - accuracy: 0.7416 - val_loss: 1.7179 - val_accuracy: 0.7436\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7195 - accuracy: 0.7425 - val_loss: 1.7168 - val_accuracy: 0.7450\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7197 - accuracy: 0.7426 - val_loss: 1.7158 - val_accuracy: 0.7460\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7195 - accuracy: 0.7423 - val_loss: 1.7196 - val_accuracy: 0.7426\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7195 - accuracy: 0.7425 - val_loss: 1.7174 - val_accuracy: 0.7436\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7192 - accuracy: 0.7429 - val_loss: 1.7165 - val_accuracy: 0.7451\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7191 - accuracy: 0.7429 - val_loss: 1.7164 - val_accuracy: 0.7462\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7185 - accuracy: 0.7437 - val_loss: 1.7171 - val_accuracy: 0.7442\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7186 - accuracy: 0.7433 - val_loss: 1.7152 - val_accuracy: 0.7466\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7182 - accuracy: 0.7437 - val_loss: 1.7130 - val_accuracy: 0.7495\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7180 - accuracy: 0.7440 - val_loss: 1.7174 - val_accuracy: 0.7439\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7178 - accuracy: 0.7440 - val_loss: 1.7146 - val_accuracy: 0.7461\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7173 - accuracy: 0.7449 - val_loss: 1.7155 - val_accuracy: 0.7467\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7175 - accuracy: 0.7442 - val_loss: 1.7184 - val_accuracy: 0.7428\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7175 - accuracy: 0.7444 - val_loss: 1.7152 - val_accuracy: 0.7464\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7172 - accuracy: 0.7445 - val_loss: 1.7155 - val_accuracy: 0.7469\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7169 - accuracy: 0.7446 - val_loss: 1.7152 - val_accuracy: 0.7457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4it [09:59, 128.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7302 - accuracy: 0.7323 - val_loss: 1.7265 - val_accuracy: 0.7360\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7295 - accuracy: 0.7327 - val_loss: 1.7259 - val_accuracy: 0.7358\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7291 - accuracy: 0.7331 - val_loss: 1.7246 - val_accuracy: 0.7369\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7287 - accuracy: 0.7327 - val_loss: 1.7242 - val_accuracy: 0.7381\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7274 - accuracy: 0.7350 - val_loss: 1.7249 - val_accuracy: 0.7371\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7272 - accuracy: 0.7355 - val_loss: 1.7224 - val_accuracy: 0.7396\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7268 - accuracy: 0.7355 - val_loss: 1.7226 - val_accuracy: 0.7388\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7256 - accuracy: 0.7369 - val_loss: 1.7248 - val_accuracy: 0.7378\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7254 - accuracy: 0.7367 - val_loss: 1.7221 - val_accuracy: 0.7396\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7251 - accuracy: 0.7367 - val_loss: 1.7226 - val_accuracy: 0.7392\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7241 - accuracy: 0.7379 - val_loss: 1.7242 - val_accuracy: 0.7369\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7241 - accuracy: 0.7379 - val_loss: 1.7207 - val_accuracy: 0.7414\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7237 - accuracy: 0.7383 - val_loss: 1.7196 - val_accuracy: 0.7422\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7227 - accuracy: 0.7394 - val_loss: 1.7208 - val_accuracy: 0.7414\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7228 - accuracy: 0.7398 - val_loss: 1.7191 - val_accuracy: 0.7433\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7228 - accuracy: 0.7392 - val_loss: 1.7195 - val_accuracy: 0.7424\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7222 - accuracy: 0.7398 - val_loss: 1.7188 - val_accuracy: 0.7422\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7214 - accuracy: 0.7405 - val_loss: 1.7189 - val_accuracy: 0.7424\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7216 - accuracy: 0.7404 - val_loss: 1.7194 - val_accuracy: 0.7418\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7214 - accuracy: 0.7402 - val_loss: 1.7188 - val_accuracy: 0.7436\n",
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7208 - accuracy: 0.7413 - val_loss: 1.7208 - val_accuracy: 0.7407\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7208 - accuracy: 0.7412 - val_loss: 1.7168 - val_accuracy: 0.7453\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7200 - accuracy: 0.7418 - val_loss: 1.7161 - val_accuracy: 0.7471\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7198 - accuracy: 0.7420 - val_loss: 1.7175 - val_accuracy: 0.7443\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7199 - accuracy: 0.7421 - val_loss: 1.7180 - val_accuracy: 0.7450\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7195 - accuracy: 0.7424 - val_loss: 1.7169 - val_accuracy: 0.7456\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7197 - accuracy: 0.7422 - val_loss: 1.7176 - val_accuracy: 0.7447\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7189 - accuracy: 0.7431 - val_loss: 1.7170 - val_accuracy: 0.7460\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7190 - accuracy: 0.7431 - val_loss: 1.7154 - val_accuracy: 0.7458\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7179 - accuracy: 0.7440 - val_loss: 1.7160 - val_accuracy: 0.7464\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7180 - accuracy: 0.7442 - val_loss: 1.7149 - val_accuracy: 0.7464\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7180 - accuracy: 0.7438 - val_loss: 1.7152 - val_accuracy: 0.7474\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7179 - accuracy: 0.7438 - val_loss: 1.7172 - val_accuracy: 0.7446\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7182 - accuracy: 0.7440 - val_loss: 1.7138 - val_accuracy: 0.7481\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7175 - accuracy: 0.7444 - val_loss: 1.7142 - val_accuracy: 0.7475\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7171 - accuracy: 0.7448 - val_loss: 1.7167 - val_accuracy: 0.7445\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7168 - accuracy: 0.7452 - val_loss: 1.7148 - val_accuracy: 0.7473\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7165 - accuracy: 0.7457 - val_loss: 1.7152 - val_accuracy: 0.7462\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7166 - accuracy: 0.7454 - val_loss: 1.7135 - val_accuracy: 0.7477\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7166 - accuracy: 0.7453 - val_loss: 1.7156 - val_accuracy: 0.7450\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7167 - accuracy: 0.7449 - val_loss: 1.7141 - val_accuracy: 0.7478\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7165 - accuracy: 0.7454 - val_loss: 1.7138 - val_accuracy: 0.7477\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7157 - accuracy: 0.7462 - val_loss: 1.7134 - val_accuracy: 0.7480\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7159 - accuracy: 0.7458 - val_loss: 1.7159 - val_accuracy: 0.7456\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7159 - accuracy: 0.7460 - val_loss: 1.7149 - val_accuracy: 0.7464\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7153 - accuracy: 0.7465 - val_loss: 1.7140 - val_accuracy: 0.7477\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7152 - accuracy: 0.7467 - val_loss: 1.7146 - val_accuracy: 0.7463\n",
      "Epoch 28/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7147 - accuracy: 0.7472 - val_loss: 1.7147 - val_accuracy: 0.7467\n",
      "Epoch 29/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7144 - accuracy: 0.7474 - val_loss: 1.7133 - val_accuracy: 0.7477\n",
      "Epoch 30/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7146 - accuracy: 0.7471 - val_loss: 1.7127 - val_accuracy: 0.7483\n",
      "Epoch 31/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7146 - accuracy: 0.7472 - val_loss: 1.7129 - val_accuracy: 0.7486\n",
      "Epoch 32/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7143 - accuracy: 0.7472 - val_loss: 1.7124 - val_accuracy: 0.7483\n",
      "Epoch 33/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7145 - accuracy: 0.7472 - val_loss: 1.7133 - val_accuracy: 0.7484\n",
      "Epoch 34/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7142 - accuracy: 0.7476 - val_loss: 1.7126 - val_accuracy: 0.7492\n",
      "Epoch 35/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7139 - accuracy: 0.7477 - val_loss: 1.7122 - val_accuracy: 0.7496\n",
      "Epoch 36/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7135 - accuracy: 0.7487 - val_loss: 1.7124 - val_accuracy: 0.7487\n",
      "Epoch 37/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7140 - accuracy: 0.7480 - val_loss: 1.7127 - val_accuracy: 0.7490\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7135 - accuracy: 0.7481 - val_loss: 1.7118 - val_accuracy: 0.7488\n",
      "Epoch 39/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7136 - accuracy: 0.7480 - val_loss: 1.7115 - val_accuracy: 0.7491\n",
      "Epoch 40/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7129 - accuracy: 0.7489 - val_loss: 1.7117 - val_accuracy: 0.7501\n",
      "Epoch 41/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7131 - accuracy: 0.7486 - val_loss: 1.7113 - val_accuracy: 0.7505\n",
      "Epoch 42/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7135 - accuracy: 0.7478 - val_loss: 1.7112 - val_accuracy: 0.7497\n",
      "Epoch 43/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7136 - accuracy: 0.7483 - val_loss: 1.7118 - val_accuracy: 0.7499\n",
      "Epoch 44/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7132 - accuracy: 0.7484 - val_loss: 1.7117 - val_accuracy: 0.7499\n",
      "Epoch 45/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7123 - accuracy: 0.7497 - val_loss: 1.7101 - val_accuracy: 0.7513\n",
      "Epoch 46/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7122 - accuracy: 0.7493 - val_loss: 1.7120 - val_accuracy: 0.7496\n",
      "Epoch 47/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7117 - accuracy: 0.7500 - val_loss: 1.7116 - val_accuracy: 0.7494\n",
      "Epoch 48/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7130 - accuracy: 0.7485 - val_loss: 1.7119 - val_accuracy: 0.7495\n",
      "Epoch 49/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7115 - accuracy: 0.7505 - val_loss: 1.7110 - val_accuracy: 0.7500\n",
      "Epoch 50/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7116 - accuracy: 0.7498 - val_loss: 1.7121 - val_accuracy: 0.7493\n",
      "Epoch 51/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7120 - accuracy: 0.7494 - val_loss: 1.7097 - val_accuracy: 0.7522\n",
      "Epoch 52/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7119 - accuracy: 0.7497 - val_loss: 1.7103 - val_accuracy: 0.7509\n",
      "Epoch 53/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7113 - accuracy: 0.7501 - val_loss: 1.7099 - val_accuracy: 0.7513\n",
      "Epoch 54/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7110 - accuracy: 0.7509 - val_loss: 1.7118 - val_accuracy: 0.7493\n",
      "Epoch 55/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7112 - accuracy: 0.7507 - val_loss: 1.7105 - val_accuracy: 0.7506\n",
      "Epoch 56/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7109 - accuracy: 0.7505 - val_loss: 1.7103 - val_accuracy: 0.7507\n",
      "Epoch 57/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7110 - accuracy: 0.7507 - val_loss: 1.7104 - val_accuracy: 0.7506\n",
      "Epoch 58/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7112 - accuracy: 0.7505 - val_loss: 1.7103 - val_accuracy: 0.7512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "5it [13:39, 155.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7308 - accuracy: 0.7314 - val_loss: 1.7256 - val_accuracy: 0.7366\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7295 - accuracy: 0.7332 - val_loss: 1.7268 - val_accuracy: 0.7359\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7288 - accuracy: 0.7338 - val_loss: 1.7277 - val_accuracy: 0.7350\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7286 - accuracy: 0.7339 - val_loss: 1.7246 - val_accuracy: 0.7377\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7274 - accuracy: 0.7347 - val_loss: 1.7248 - val_accuracy: 0.7371\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7266 - accuracy: 0.7357 - val_loss: 1.7243 - val_accuracy: 0.7375\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7265 - accuracy: 0.7354 - val_loss: 1.7242 - val_accuracy: 0.7377\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7265 - accuracy: 0.7355 - val_loss: 1.7232 - val_accuracy: 0.7380\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7252 - accuracy: 0.7370 - val_loss: 1.7222 - val_accuracy: 0.7407\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7246 - accuracy: 0.7376 - val_loss: 1.7213 - val_accuracy: 0.7414\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7253 - accuracy: 0.7367 - val_loss: 1.7203 - val_accuracy: 0.7419\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7241 - accuracy: 0.7378 - val_loss: 1.7196 - val_accuracy: 0.7420\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7237 - accuracy: 0.7380 - val_loss: 1.7213 - val_accuracy: 0.7401\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7228 - accuracy: 0.7395 - val_loss: 1.7231 - val_accuracy: 0.7384\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7235 - accuracy: 0.7386 - val_loss: 1.7197 - val_accuracy: 0.7425\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7222 - accuracy: 0.7399 - val_loss: 1.7206 - val_accuracy: 0.7412\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7222 - accuracy: 0.7396 - val_loss: 1.7189 - val_accuracy: 0.7428\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7216 - accuracy: 0.7404 - val_loss: 1.7174 - val_accuracy: 0.7446\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7217 - accuracy: 0.7402 - val_loss: 1.7190 - val_accuracy: 0.7433\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7207 - accuracy: 0.7414 - val_loss: 1.7183 - val_accuracy: 0.7436\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7211 - accuracy: 0.7409 - val_loss: 1.7195 - val_accuracy: 0.7428\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7203 - accuracy: 0.7418 - val_loss: 1.7220 - val_accuracy: 0.7406\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7198 - accuracy: 0.7421 - val_loss: 1.7176 - val_accuracy: 0.7445\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7200 - accuracy: 0.7423 - val_loss: 1.7168 - val_accuracy: 0.7446\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7194 - accuracy: 0.7424 - val_loss: 1.7159 - val_accuracy: 0.7456\n",
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7190 - accuracy: 0.7429 - val_loss: 1.7178 - val_accuracy: 0.7436\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7193 - accuracy: 0.7424 - val_loss: 1.7174 - val_accuracy: 0.7437\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7186 - accuracy: 0.7433 - val_loss: 1.7159 - val_accuracy: 0.7463\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7190 - accuracy: 0.7431 - val_loss: 1.7149 - val_accuracy: 0.7473\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7184 - accuracy: 0.7432 - val_loss: 1.7154 - val_accuracy: 0.7459\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7186 - accuracy: 0.7434 - val_loss: 1.7151 - val_accuracy: 0.7472\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7175 - accuracy: 0.7445 - val_loss: 1.7154 - val_accuracy: 0.7462\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7177 - accuracy: 0.7441 - val_loss: 1.7155 - val_accuracy: 0.7461\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7176 - accuracy: 0.7443 - val_loss: 1.7149 - val_accuracy: 0.7478\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7172 - accuracy: 0.7449 - val_loss: 1.7153 - val_accuracy: 0.7463\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7172 - accuracy: 0.7444 - val_loss: 1.7144 - val_accuracy: 0.7466\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7169 - accuracy: 0.7455 - val_loss: 1.7158 - val_accuracy: 0.7463\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7166 - accuracy: 0.7448 - val_loss: 1.7149 - val_accuracy: 0.7463\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7165 - accuracy: 0.7453 - val_loss: 1.7154 - val_accuracy: 0.7471\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7165 - accuracy: 0.7453 - val_loss: 1.7149 - val_accuracy: 0.7459\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7164 - accuracy: 0.7456 - val_loss: 1.7138 - val_accuracy: 0.7468\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7155 - accuracy: 0.7460 - val_loss: 1.7133 - val_accuracy: 0.7480\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7159 - accuracy: 0.7457 - val_loss: 1.7136 - val_accuracy: 0.7483\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7157 - accuracy: 0.7462 - val_loss: 1.7132 - val_accuracy: 0.7478\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7154 - accuracy: 0.7465 - val_loss: 1.7138 - val_accuracy: 0.7479\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7152 - accuracy: 0.7469 - val_loss: 1.7129 - val_accuracy: 0.7483\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7152 - accuracy: 0.7466 - val_loss: 1.7133 - val_accuracy: 0.7475\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7154 - accuracy: 0.7463 - val_loss: 1.7121 - val_accuracy: 0.7504\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7139 - accuracy: 0.7482 - val_loss: 1.7133 - val_accuracy: 0.7483\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7145 - accuracy: 0.7472 - val_loss: 1.7120 - val_accuracy: 0.7492\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7150 - accuracy: 0.7467 - val_loss: 1.7118 - val_accuracy: 0.7494\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7143 - accuracy: 0.7476 - val_loss: 1.7125 - val_accuracy: 0.7489\n",
      "Epoch 28/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7145 - accuracy: 0.7473 - val_loss: 1.7115 - val_accuracy: 0.7496\n",
      "Epoch 29/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7141 - accuracy: 0.7479 - val_loss: 1.7154 - val_accuracy: 0.7461\n",
      "Epoch 30/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7138 - accuracy: 0.7481 - val_loss: 1.7110 - val_accuracy: 0.7501\n",
      "Epoch 31/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7141 - accuracy: 0.7477 - val_loss: 1.7119 - val_accuracy: 0.7496\n",
      "Epoch 32/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7135 - accuracy: 0.7482 - val_loss: 1.7114 - val_accuracy: 0.7494\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7130 - accuracy: 0.7488 - val_loss: 1.7111 - val_accuracy: 0.7503\n",
      "Epoch 34/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7134 - accuracy: 0.7480 - val_loss: 1.7105 - val_accuracy: 0.7510\n",
      "Epoch 35/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7131 - accuracy: 0.7487 - val_loss: 1.7109 - val_accuracy: 0.7504\n",
      "Epoch 36/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7126 - accuracy: 0.7492 - val_loss: 1.7107 - val_accuracy: 0.7512\n",
      "Epoch 37/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.7133 - accuracy: 0.7489 - val_loss: 1.7114 - val_accuracy: 0.7487\n",
      "Epoch 38/100\n",
      "521/938 [===============>..............] - ETA: 1s - loss: 1.7131 - accuracy: 0.7492"
     ]
    }
   ],
   "source": [
    "pgd_success_rates = []\n",
    "cw_success_rates = []\n",
    "all_accuracies = []\n",
    "\n",
    "compression_rates = [1, 2, 4, 8, 16, 32, 64]\n",
    "pruning_ratios = [1-1/x for x in compression_rates]\n",
    "    \n",
    "for j in tqdm(range(ITERATIONS)):\n",
    "    accuracies = []\n",
    "    pgd_success_rate = []\n",
    "    cw_success_rate = []e\n",
    "    model = initialize_base_model(j, save_weights=True)\n",
    "    for index, pruning_ratio in tqdm(enumerate(pruning_ratios)):\n",
    "        model.load_weights(f'./saved-weights/{EXPERIMENT_NAME}-{j}')\n",
    "        for i in range(index + 1):\n",
    "            if i != index:\n",
    "                model.prune_locally(pruning_ratios[i])\n",
    "                model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) ,\n",
    "                              metrics=['accuracy'],\n",
    "                              experimental_run_tf_function=False\n",
    "                             )\n",
    "                model = train_model(model, to_convergence=False)\n",
    "            if i == index:\n",
    "                print('final pruning and eval')\n",
    "                model.prune_locally(pruning_ratios[i])\n",
    "                model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) ,\n",
    "                              metrics=['accuracy'],\n",
    "                              experimental_run_tf_function=False\n",
    "                             )\n",
    "                model = train_model(model, to_convergence=True)\n",
    "                accuracies.append(model.evaluate(x_test, y_test, verbose=0))\n",
    "                pgd_success_rate.append(pgd_attack(model))\n",
    "                #cw_success_rate.append(cw2_attack(model))\n",
    "                \n",
    "    all_accuracies.append(accuracies)\n",
    "    pgd_success_rates.append(pgd_success_rate)\n",
    "    cw_success_rates.append(cw_success_rate)\n",
    "#write to csv and json\n",
    "\n",
    "pd.DataFrame(all_accuracies).to_csv(f'saved-results/{EXPERIMENT_NAME}-accuracies.csv',index=False)\n",
    "with open(f'saved-results/{EXPERIMENT_NAME}-accuracies.json', 'w') as f:\n",
    "    json.dump(all_accuracies, f)\n",
    "    \n",
    "pd.DataFrame(pgd_success_rates).to_csv(f'saved-results/{EXPERIMENT_NAME}-pgd-success.csv',index=False)\n",
    "with open(f'saved-results/{EXPERIMENT_NAME}-pgd-success.json', 'w') as f:\n",
    "    json.dump(pgd_success_rates, f)\n",
    "pd.DataFrame(cw_success_rates).to_csv(f'saved-results/{EXPERIMENT_NAME}-cw0-success.csv',index=False)\n",
    "with open(f'saved-results/{EXPERIMENT_NAME}-cw0-success', 'w') as f:\n",
    "    json.dump(cw_success_rates, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_base_model(index, save_weights=False):\n",
    "    model = CustomConvModel()\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) ,\n",
    "                  metrics=['accuracy'],\n",
    "                  experimental_run_tf_function=False\n",
    "\n",
    "                 )\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "    model.fit(x=x_train,\n",
    "              y=y_train,\n",
    "              batch_size=64,\n",
    "              epochs=1,\n",
    "              callbacks=[callback],\n",
    "              validation_data=(x_test, y_test),\n",
    "             )\n",
    "    if save_weights == True:\n",
    "        model.save_weights(f'./saved-weights/{EXPERIMENT_NAME}-{index}')\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, to_convergence=True):\n",
    "    if to_convergence == True:\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=7)\n",
    "        model.fit(\n",
    "            x=x_train,\n",
    "            y=y_train,\n",
    "            batch_size=64,\n",
    "            epochs=MAX_EPOCHS,\n",
    "            callbacks=[callback],\n",
    "            validation_data=(x_test, y_test),\n",
    "            )\n",
    "    if to_convergence == False:\n",
    "        model.fit(\n",
    "            x=x_train,\n",
    "            y=y_train,\n",
    "            batch_size=64,\n",
    "            epochs=5,\n",
    "            validation_data=(x_test, y_test),\n",
    "            )\n",
    "    return model\n",
    "\n",
    "def prune_weights(model, pruning_ratio):\n",
    "    weights = model.get_weights()\n",
    "    weights_to_prune = model.get_weights()\n",
    "    for index, weight in enumerate(weights):\n",
    "        \n",
    "        if (index == 9) or (index == 12) :\n",
    "            #print(weight.shape)\n",
    "            #print(index)\n",
    "            flat_weights = weight.flatten()\n",
    "            flat_weights_to_prune = weights_to_prune[index+2].flatten()\n",
    "            #print (flat_weights_to_prune.shape, flat_weights.shape)\n",
    "            flat_weights_df = pd.DataFrame(flat_weights)\n",
    "            flat_weights_to_prune_df = pd.DataFrame(flat_weights_to_prune)\n",
    "            no_of_weights_to_prune = int(len(flat_weights)*pruning_ratio)\n",
    "            #print(len(flat_weights))\n",
    "            #print('no of weights',no_of_weights_to_prune)\n",
    "            #print('weights to prune shape', flat_weights_to_prune.shape)\n",
    "            indices_to_delete = flat_weights_df.abs().values.argsort(0)[:no_of_weights_to_prune]\n",
    "            for idx_to_delete in indices_to_delete:\n",
    "                flat_weights_to_prune[idx_to_delete] = 0\n",
    "            dims = weights_to_prune[index+2].shape\n",
    "            weights_reshaped = flat_weights_to_prune.reshape(dims)\n",
    "            weights_to_prune[index+2] = weights_reshaped\n",
    "    #print(weights_to_prune)\n",
    "    return weights_to_prune\n",
    "\n",
    "def pgd_attack(model_to_attack):\n",
    "    fmodel = fb.models.TensorFlowModel(model_to_attack, bounds=(0,1))\n",
    "    attack = fb.attacks.LinfProjectedGradientDescentAttack()\n",
    "    adversarials = attack(\n",
    "        fmodel,\n",
    "        x,\n",
    "        y,\n",
    "        epsilons=[25/255]\n",
    "    )\n",
    "    return np.count_nonzero(adversarials[2])/500\n",
    "\n",
    "def cw2_attack(model_to_attack):\n",
    "    fmodel = fb.models.TensorFlowModel(model_to_attack, bounds=(0,1))\n",
    "    attack = fb.attacks.L2CarliniWagnerAttack()\n",
    "    adversarials = attack(\n",
    "        fmodel,\n",
    "        x,\n",
    "        y,\n",
    "        #epsilons=[.5]\n",
    "        epsilons=None\n",
    "    )\n",
    "    return np.count_nonzero(adversarials[2])/len(y)\n",
    "\n",
    "def prune_conv_layers(pruning_ratio):\n",
    "    layer_to_prune = [0, 3]\n",
    "    pruned_weights = model.get_weights()\n",
    "    \n",
    "    for layer in layer_to_prune:\n",
    "        converted_weights = convert_from_hwio_to_iohw(model.get_weights()[layer])\n",
    "        converted_mask = convert_from_hwio_to_iohw(model.get_weights()[layer + 2]).numpy()\n",
    "        for input_index, input_layer in enumerate(converted_weights):\n",
    "\n",
    "            for kernel_index, kernel in enumerate(input_layer):\n",
    "                dims = kernel.shape\n",
    "                flat_weights = kernel.numpy().flatten()\n",
    "                flat_masks = converted_mask[input_index][kernel_index].flatten()\n",
    "                flat_weights_df = pd.DataFrame(flat_weights)\n",
    "                flat_mask_df = pd.DataFrame(flat_masks)\n",
    "                no_of_weights_to_prune = int(len(flat_weights)*pruning_ratio)\n",
    "                #print(no_of_weights_to_prune)\n",
    "                indices_to_delete = flat_weights_df.abs().values.argsort(0)[:no_of_weights_to_prune]\n",
    "                for idx_to_delete in indices_to_delete:\n",
    "                    flat_masks[idx_to_delete] = 0\n",
    "\n",
    "                converted_mask[input_index][kernel_index] = flat_masks.reshape(dims)\n",
    "        back_converted_mask = convert_from_iohw_to_hwio(converted_mask)\n",
    "        pruned_weights[layer+2] = back_converted_mask\n",
    "    \n",
    "    return pruned_weights\n",
    "\n",
    "def convert_from_hwio_to_iohw(weights_nchw):\n",
    "    return tf.transpose(weights_nchw, [2, 3, 0, 1])\n",
    "\n",
    "\n",
    "\n",
    "def convert_from_iohw_to_hwio(weights_nhwc):\n",
    "    return tf.transpose(weights_nhwc, [2, 3, 0, 1])\n",
    "\n",
    "\n",
    "def get_average_accuracies(all_accuracies):\n",
    "    acc_per_pruning_rate=[]\n",
    "    for i in range(len(all_accuracies)):\n",
    "        for j in range(len(all_accuracies[i])):\n",
    "\n",
    "            try:\n",
    "                acc_per_pruning_rate[j].append(all_accuracies[i][j][1])\n",
    "            except:\n",
    "                acc_per_pruning_rate.append([])\n",
    "                acc_per_pruning_rate[j].append(all_accuracies[i][j][1])\n",
    "    avg_acc_per_pruning_rate = [sum(x)/len(x) for x in acc_per_pruning_rate]; avg_acc_per_pruning_rate\n",
    "    return avg_acc_per_pruning_rate\n",
    "\n",
    "def get_average_success_rates(all_success_rates):\n",
    "    success_per_pruning_rate=[]\n",
    "    for i in range(len(all_success_rates)):\n",
    "        for j in range(len(all_success_rates[i])):\n",
    "\n",
    "            try:\n",
    "                success_per_pruning_rate[j].append(all_success_rates[i][j])\n",
    "            except:\n",
    "                success_per_pruning_rate.append([])\n",
    "                success_per_pruning_rate[j].append(all_success_rates[i][j])\n",
    "    avg_success_per_pruning_rate = [sum(x)/len(x) for x in success_per_pruning_rate];avg_success_per_pruning_rate\n",
    "    return avg_success_per_pruning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
    "\n",
    "x = tf.convert_to_tensor(x_train[:500].reshape(500,28*28))\n",
    "y = tf.convert_to_tensor([y_train[:500]])[0];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    # 5x5 conv, 1 input, 6 outputs\n",
    "    'weights_conv_1': tf.Variable(tf.random.normal([5, 5, 1, 6])),\n",
    "    # 5x5 conv, 6 inputs, 16 outputs\n",
    "    'weights_conv_2': tf.Variable(tf.random.normal([5, 5, 6, 16])),\n",
    "    #5x5 conv as in paper, 16 inputs, 120 outputs\n",
    "    'weights_conv_3': tf.Variable(tf.random.normal([1, 1, 16, 120])),\n",
    "    # fully connected, 5*5*16 inputs, 120 outputs\n",
    "    'weights_dense_1': tf.Variable(tf.random.normal([5*5*16, 120])),\n",
    "    # fully connected, 120 inputs, 84 outputs\n",
    "    'weights_dense_2': tf.Variable(tf.random.normal([120, 84])),\n",
    "    # 84 inputs, 10 outputs (class prediction)\n",
    "    'weights_dense_3': tf.Variable(tf.random.normal([84, 10])),\n",
    "}\n",
    "\n",
    "masks = {\n",
    "    # 5x5 conv, 1 input, 6 outputs\n",
    "    'mask_conv_1': tf.Variable(tf.ones([5, 5, 1, 6]), trainable=False),\n",
    "    # 5x5 conv, 6 inputs, 16 outputs\n",
    "    'mask_conv_2': tf.Variable(tf.ones([5, 5, 6, 16]), trainable=False),\n",
    "    #5x5 conv as in paper, 16 inputs, 120 outputs\n",
    "    'mask_conv_3': tf.Variable(tf.ones([1, 1, 16, 120]), trainable=False),\n",
    "    # fully connected, 5*5*16 inputs, 120 outputs\n",
    "    'mask_dense_1': tf.Variable(tf.ones([5*5*16, 120]), trainable=False),\n",
    "    # fully connected, 120 inputs, 84 outputs\n",
    "    'mask_dense_2': tf.Variable(tf.ones([120, 84]), trainable=False),\n",
    "    # 84 inputs, 10 outputs (class prediction)\n",
    "    'mask_dense_3': tf.Variable(tf.ones([84, 10]), trainable=False),\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    #output depth\n",
    "    'bias_conv_1': tf.Variable(tf.random.normal([6])),\n",
    "    'bias_conv_2': tf.Variable(tf.random.normal([16])),\n",
    "    'bias_dense_1': tf.Variable(tf.random.normal([120])),\n",
    "    'bias_dense_2': tf.Variable(tf.random.normal([84])),\n",
    "    'bias_dense_3': tf.Variable(tf.random.normal([10])),\n",
    "}\n",
    "\n",
    "#conv2D with bias and relu activation\n",
    "\n",
    "class CustomConvLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, weights, mask, biases, strides, padding='SAME'):\n",
    "        \n",
    "        super(CustomConvLayer, self).__init__()\n",
    "        self.w = weights\n",
    "        self.m = mask\n",
    "        self.b = biases\n",
    "        self.s = strides\n",
    "        self.p = padding\n",
    "\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.nn.conv2d(inputs, tf.multiply(self.w, self.m), strides=[1, self.s, self.s, 1], padding=self.p,)# data_format='NCHW')\n",
    "        x = tf.nn.bias_add(x, self.b,)# 'NC...')\n",
    "        return tf.nn.tanh(x)\n",
    "        \n",
    "\n",
    "#Average Pooling Layer\n",
    "class CustomPoolLayer(layers.Layer):\n",
    "    \n",
    "    def __init__(self, k=2, padding='valid'):#padding='VALID'):\n",
    "        super(CustomPoolLayer, self).__init__()\n",
    "        self.k = k\n",
    "        self.p = padding\n",
    "    \n",
    "    def call(self, inputs):\n",
    "#        return tf.keras.layers.AveragePooling2D(pool_size=(self.k, self.k), strides=None, padding=self.p, data_format='channels_first')(inputs)\n",
    "        return tf.nn.avg_pool2d(inputs, ksize=[1, self.k, self.k,1], strides=[1, self.k, self.k, 1], padding=self.p,)# data_format='NCHW')\n",
    "    \n",
    "#Dense Layer with Bias\n",
    "class CustomDenseLayer(layers.Layer):\n",
    "    \n",
    "    def __init__(self, weights, mask, bias, activation = 'tanh'):\n",
    "        super(CustomDenseLayer, self).__init__()\n",
    "        self.w = weights\n",
    "        self.b = bias\n",
    "        self.a = activation\n",
    "        self.m = mask\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.matmul(inputs, tf.multiply(self.w, self.m))\n",
    "        x = tf.nn.bias_add(x, self.b)\n",
    "        if self.a == 'tanh':\n",
    "            return tf.nn.tanh(x)\n",
    "        if self.a == 'softmax':\n",
    "            return tf.nn.softmax(x)\n",
    "        \n",
    "class CustomConvModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CustomConvModel, self).__init__()\n",
    "        self.conv1 = CustomConvLayer(weights['weights_conv_1'], masks['mask_conv_1'], biases['bias_conv_1'], 1, 'SAME')#'VALID')\n",
    "        self.maxpool1 = CustomPoolLayer(k=2, padding='SAME')\n",
    "        self.conv2 = CustomConvLayer(weights['weights_conv_2'], masks['mask_conv_2'], biases['bias_conv_2'], 1, 'VALID')\n",
    "        self.maxpool2 = CustomPoolLayer(k=2, padding='VALID')\n",
    "        #self.conv3 = CustomConvLayer(weights['weights_conv_3'], masks['mask_conv_3'], biases['bias_dense_1'], 1, 'VALID')\n",
    "        self.dense1 = CustomDenseLayer(weights['weights_dense_1'], masks['mask_dense_1'], biases['bias_dense_1'], 'tanh')\n",
    "        self.dense2 = CustomDenseLayer(weights['weights_dense_2'], masks['mask_dense_2'], biases['bias_dense_2'], 'tanh')\n",
    "        self.dense3 = CustomDenseLayer(weights['weights_dense_3'], masks['mask_dense_3'], biases['bias_dense_3'], 'softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.reshape(inputs, shape=[-1,28, 28, 1])\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = layers.Flatten()(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x =  self.dense3(x)\n",
    "        return x\n",
    "    \n",
    "    def prune_randomly(self, ratio):\n",
    "        def prune_conv_layers_locally(self, ratio):\n",
    "            conv_layer_to_prune = [0, 3]\n",
    "            weights = model.get_weights()\n",
    "            for layer in conv_layer_to_prune:\n",
    "                converted_weights = convert_from_hwio_to_iohw(weights[layer]).numpy()\n",
    "                converted_mask = convert_from_hwio_to_iohw(weights[layer + 2]).numpy()\n",
    "                for input_index, input_layer in enumerate(converted_weights):\n",
    "                    for kernel_index, kernel in enumerate(input_layer):\n",
    "                        shape = kernel.shape\n",
    "                        flat_weights = kernel.flatten()\n",
    "                        flat_masks = converted_mask[input_index][kernel_index].flatten()\n",
    "                        \n",
    "                        no_of_weighs_to_prune = ratio * len(flat_weights)\n",
    "                        # find unpruned weights\n",
    "                        non_zero_weights = np.nonzero(flat_masks)[0]\n",
    "                        # calculate the amount of weights to be pruned this round\n",
    "                        no_of_weights_to_prune_left = int(no_of_weighs_to_prune - (len(flat_weights) - len(non_zero_weights)) )\n",
    "                        # shuffle all non-zero weights\n",
    "                        random.shuffle(non_zero_weights)\n",
    "                        # and take the indices of the first x weights where x is the number of weights to be pruned this round\n",
    "                        indices_to_delete = non_zero_weights[:no_of_weights_to_prune_left]\n",
    "                        \n",
    "                        for idx_to_delete in indices_to_delete:\n",
    "                            flat_masks[idx_to_delete] = 0\n",
    "                            flat_weights[idx_to_delete] = 0\n",
    "                        converted_mask[input_index][kernel_index] = flat_masks.reshape(shape)\n",
    "                        converted_weights[input_index][kernel_index] = flat_weights.reshape(shape)\n",
    "                back_converted_mask = convert_from_iohw_to_hwio(converted_mask)\n",
    "                back_converted_weights = convert_from_iohw_to_hwio(converted_weights)\n",
    "                weights[layer] = back_converted_weights\n",
    "                weights[layer+2] = back_converted_mask\n",
    "            self.set_weights(weights)\n",
    "            return True\n",
    "        \n",
    "        def prune_dense_layers_locally(self, ratio):\n",
    "            dense_layer_to_prune = [6, 9, 12]\n",
    "            weights = model.get_weights()\n",
    "            for index, weight in enumerate(weights):\n",
    "                if index in dense_layer_to_prune:\n",
    "                    shape = weight.shape\n",
    "                    flat_weights = weight.flatten()\n",
    "                    flat_mask = weights[index+2].flatten()\n",
    "                    no_of_weighs_to_prune = ratio * len(flat_weights)\n",
    "                    # find unpruned weights\n",
    "                    non_zero_weights = np.nonzero(flat_mask)[0]\n",
    "                    # calculate the amount of weights to be pruned this round\n",
    "                    no_of_weights_to_prune_left = int(no_of_weighs_to_prune - (len(flat_weights) - len(non_zero_weights)) )\n",
    "                    # shuffle all non-zero weights\n",
    "                    random.shuffle(non_zero_weights)\n",
    "                    # and take the indices of the first x weights where x is the number of weights to be pruned this round\n",
    "                    indices_to_delete = non_zero_weights[:no_of_weights_to_prune_left]\n",
    "                    for idx_to_delete in indices_to_delete:\n",
    "                        flat_mask[idx_to_delete] = 0\n",
    "                        flat_weights[idx_to_delete] = 0\n",
    "\n",
    "                    mask_reshaped = flat_mask.reshape(shape)\n",
    "                    weights_reshaped = flat_weights.reshape(shape)\n",
    "                    weights[index+2] = mask_reshaped\n",
    "                    weights[index] = weights_reshaped\n",
    "            self.set_weights(weights)\n",
    "            return True\n",
    "        prune_conv_layers_locally(self, ratio)\n",
    "        prune_dense_layers_locally(self,ratio)\n",
    "    \n",
    "    def prune_globally(self, ratio):\n",
    "        #flat out all weights:\n",
    "        conv_layer_to_prune = [0, 3]\n",
    "        dense_layer_to_prune = [6, 9, 12]\n",
    "        weights = self.get_weights()\n",
    "        flat_weights = []\n",
    "        flat_mask = []\n",
    "        for x in conv_layer_to_prune + dense_layer_to_prune:\n",
    "            flat_weights = np.append(flat_weights, weights[x])\n",
    "            flat_mask = np.append(flat_mask, weights[x+2])\n",
    "            \n",
    "        no_of_weights_to_prune = int(len(flat_weights)*ratio)\n",
    "        indices_to_delete = np.abs(flat_weights).argsort(0)[:no_of_weights_to_prune]\n",
    "        \n",
    "        for idx_to_delete in indices_to_delete:\n",
    "            flat_mask[idx_to_delete] = 0\n",
    "            flat_weights[idx_to_delete] = 0\n",
    "        z = 0\n",
    "        for x in conv_layer_to_prune + dense_layer_to_prune:\n",
    "            weights[x] = flat_weights[z:z + np.prod(weights[x].shape)].reshape(weights[x].shape)\n",
    "            weights[x + 2] = flat_mask[z:z + np.prod(weights[x].shape)].reshape(weights[x].shape)\n",
    "            z = z + np.prod(weights[x].shape)            \n",
    "        self.set_weights(weights)\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "    \n",
    "    def prune_locally(self, ratio):\n",
    "        def prune_conv_layers_locally(self, ratio):\n",
    "            conv_layer_to_prune = [0, 3]\n",
    "            weights = model.get_weights()\n",
    "            for layer in conv_layer_to_prune:\n",
    "                converted_weights = convert_from_hwio_to_iohw(weights[layer]).numpy()\n",
    "                converted_mask = convert_from_hwio_to_iohw(weights[layer + 2]).numpy()\n",
    "                for input_index, input_layer in enumerate(converted_weights):\n",
    "                    for kernel_index, kernel in enumerate(input_layer):\n",
    "                        shape = kernel.shape\n",
    "                        flat_weights = kernel.flatten()\n",
    "                        flat_masks = converted_mask[input_index][kernel_index].flatten()\n",
    "                        #flat_weights_df = pd.DataFrame(flat_weights)\n",
    "                        #flat_mask_df = pd.DataFrame(flat_masks)\n",
    "                        no_of_weights_to_prune = int(len(flat_weights)*ratio)\n",
    "                        #print(no_of_weights_to_prune)\n",
    "                        #indices_to_delete = flat_weights_df.abs().values.argsort(0)[:no_of_weights_to_prune]\n",
    "                        indices_to_delete = np.abs(flat_weights).argsort(0)[:no_of_weights_to_prune]\n",
    "\n",
    "\n",
    "                        for idx_to_delete in indices_to_delete:\n",
    "                            flat_masks[idx_to_delete] = 0\n",
    "                            flat_weights[idx_to_delete] = 0\n",
    "\n",
    "                        converted_mask[input_index][kernel_index] = flat_masks.reshape(shape)\n",
    "                        converted_weights[input_index][kernel_index] = flat_weights.reshape(shape)\n",
    "                back_converted_mask = convert_from_iohw_to_hwio(converted_mask)\n",
    "                back_converted_weights = convert_from_iohw_to_hwio(converted_weights)\n",
    "                weights[layer] = back_converted_weights\n",
    "                weights[layer+2] = back_converted_mask\n",
    "            self.set_weights(weights)\n",
    "            return True\n",
    "        \n",
    "        def prune_dense_layers_locally(self, ratio):\n",
    "            dense_layer_to_prune = [6, 9, 12]\n",
    "            weights = model.get_weights()\n",
    "            for index, weight in enumerate(weights):\n",
    "                if index in dense_layer_to_prune:\n",
    "                    shape = weight.shape\n",
    "                    flat_weights = weight.flatten()\n",
    "                    flat_mask = weights[index+2].flatten()\n",
    "\n",
    "                    no_of_weights_to_prune = int(len(flat_weights)*ratio)\n",
    "                    indices_to_delete = np.abs(flat_weights).argsort()[:no_of_weights_to_prune]\n",
    "                    for idx_to_delete in indices_to_delete:\n",
    "                        flat_mask[idx_to_delete] = 0\n",
    "                        flat_weights[idx_to_delete] = 0\n",
    "\n",
    "                    mask_reshaped = flat_mask.reshape(shape)\n",
    "                    weights_reshaped = flat_weights.reshape(shape)\n",
    "                    weights[index+2] = mask_reshaped\n",
    "                    weights[index] = weights_reshaped\n",
    "            self.set_weights(weights)\n",
    "            return True\n",
    "        prune_conv_layers_locally(self,ratio)\n",
    "        prune_dense_layers_locally(self,ratio)\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node custom_conv_model/custom_conv_layer/Conv2D (defined at <ipython-input-5-d28eb1756cec>:55) ]] [Op:__inference_train_function_925]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node custom_conv_model/custom_conv_layer/Conv2D:\n custom_conv_model/Reshape (defined at <ipython-input-5-d28eb1756cec>:103)\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1292dbb0699e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m model.fit(x=x_train[:500],\n\u001b[0m\u001b[1;32m     12\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/master-thesis/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/master-thesis/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/master-thesis/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/master-thesis/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/master-thesis/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/master-thesis/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/anaconda3/envs/master-thesis/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/master-thesis/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/master-thesis/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node custom_conv_model/custom_conv_layer/Conv2D (defined at <ipython-input-5-d28eb1756cec>:55) ]] [Op:__inference_train_function_925]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node custom_conv_model/custom_conv_layer/Conv2D:\n custom_conv_model/Reshape (defined at <ipython-input-5-d28eb1756cec>:103)\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "model = CustomConvModel()\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) ,\n",
    "              metrics=['accuracy'],\n",
    "              experimental_run_tf_function=False\n",
    "              \n",
    "             )\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "model.fit(x=x_train[:500],\n",
    "          y=y_train[:500],\n",
    "          batch_size=128,\n",
    "          epochs=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(x_test, y_test),\n",
    "         )\n",
    "#model.save('./saved-models/mini-pipeline-CNN-baseline-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./saved-models/mini-pipeline-CNN-baseline-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/florianmerkle/dev/foolbox/foolbox/models/tensorflow.py:13: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.996"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pgd_attack(model_to_attack):\n",
    "    fmodel = fb.models.TensorFlowModel(model_to_attack, bounds=(0,1))\n",
    "    attack = fb.attacks.LinfProjectedGradientDescentAttack()\n",
    "    adversarials = attack(\n",
    "        fmodel,\n",
    "        x,\n",
    "        y,\n",
    "        epsilons=[25/255]\n",
    "    )\n",
    "    return np.count_nonzero(adversarials[2])/500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
